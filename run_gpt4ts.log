nohup: ignoring input
ai-gpgpu14
ğŸš€ gpt4ts | dataset=physionet_2012 | mr=0.1 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:30:48 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:30:48 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-15 15:30:48 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-15 15:30:48 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-15 15:30:48 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-15 15:30:53 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-15 15:30:54 [INFO]: 22947 values masked out in the val set as ground truth, take 9.91% of the original observed values
2025-08-15 15:30:54 [INFO]: 28724 values masked out in the test set as ground truth, take 10.08% of the original observed values
2025-08-15 15:30:54 [INFO]: Total sample number: 3997
2025-08-15 15:30:54 [INFO]: Training set size: 2557 (63.97%)
2025-08-15 15:30:54 [INFO]: Validation set size: 640 (16.01%)
2025-08-15 15:30:54 [INFO]: Test set size: 800 (20.02%)
2025-08-15 15:30:54 [INFO]: Number of steps: 48
2025-08-15 15:30:54 [INFO]: Number of features: 37
2025-08-15 15:30:54 [INFO]: Train set missing rate: 79.68%
2025-08-15 15:30:54 [INFO]: Validating set missing rate: 81.65%
2025-08-15 15:30:54 [INFO]: Test set missing rate: 81.96%
2025-08-15 15:30:54 [INFO]: Using the given device: cpu
2025-08-15 15:30:54 [INFO]: Model files will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:30:54 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:30:54 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:30:54 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:30:55 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 909,349
2025-08-15 15:30:56 [ERROR]: âŒ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'physionet_2012' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
ğŸš€ Starting GPT4TS training pipeline...
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 738, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 815, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
ğŸš€ gpt4ts | dataset=physionet_2012 | mr=0.2 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:31:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:31:14 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-15 15:31:14 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-15 15:31:14 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-15 15:31:15 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-15 15:31:20 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-15 15:31:20 [INFO]: 46041 values masked out in the val set as ground truth, take 19.88% of the original observed values
2025-08-15 15:31:20 [INFO]: 57450 values masked out in the test set as ground truth, take 20.16% of the original observed values
2025-08-15 15:31:21 [INFO]: Total sample number: 3997
2025-08-15 15:31:21 [INFO]: Training set size: 2557 (63.97%)
2025-08-15 15:31:21 [INFO]: Validation set size: 640 (16.01%)
2025-08-15 15:31:21 [INFO]: Test set size: 800 (20.02%)
2025-08-15 15:31:21 [INFO]: Number of steps: 48
2025-08-15 15:31:21 [INFO]: Number of features: 37
2025-08-15 15:31:21 [INFO]: Train set missing rate: 79.68%
2025-08-15 15:31:21 [INFO]: Validating set missing rate: 83.68%
2025-08-15 15:31:21 [INFO]: Test set missing rate: 83.99%
2025-08-15 15:31:21 [INFO]: Using the given device: cpu
2025-08-15 15:31:21 [INFO]: Model files will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:31:21 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:31:21 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:31:21 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:31:21 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 909,349
2025-08-15 15:31:22 [ERROR]: âŒ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'physionet_2012' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
ğŸš€ Starting GPT4TS training pipeline...
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 738, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 815, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
ğŸš€ gpt4ts | dataset=physionet_2012 | mr=0.3 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:31:41 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:31:41 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-15 15:31:41 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-15 15:31:41 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-15 15:31:41 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-15 15:31:47 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-15 15:31:47 [INFO]: 69227 values masked out in the val set as ground truth, take 29.90% of the original observed values
2025-08-15 15:31:47 [INFO]: 85805 values masked out in the test set as ground truth, take 30.11% of the original observed values
2025-08-15 15:31:47 [INFO]: Total sample number: 3997
2025-08-15 15:31:47 [INFO]: Training set size: 2557 (63.97%)
2025-08-15 15:31:47 [INFO]: Validation set size: 640 (16.01%)
2025-08-15 15:31:47 [INFO]: Test set size: 800 (20.02%)
2025-08-15 15:31:47 [INFO]: Number of steps: 48
2025-08-15 15:31:47 [INFO]: Number of features: 37
2025-08-15 15:31:47 [INFO]: Train set missing rate: 79.68%
2025-08-15 15:31:47 [INFO]: Validating set missing rate: 85.72%
2025-08-15 15:31:47 [INFO]: Test set missing rate: 85.98%
2025-08-15 15:31:47 [INFO]: Using the given device: cpu
2025-08-15 15:31:47 [INFO]: Model files will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:31:47 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:31:47 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:31:47 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:31:48 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 909,349
2025-08-15 15:31:49 [ERROR]: âŒ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'physionet_2012' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
ğŸš€ Starting GPT4TS training pipeline...
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 738, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 815, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
ğŸš€ gpt4ts | dataset=physionet_2012 | mr=0.4 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:32:08 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:32:08 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-15 15:32:08 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-15 15:32:08 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-15 15:32:08 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-15 15:32:14 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-15 15:32:14 [INFO]: 92507 values masked out in the val set as ground truth, take 39.95% of the original observed values
2025-08-15 15:32:14 [INFO]: 114242 values masked out in the test set as ground truth, take 40.09% of the original observed values
2025-08-15 15:32:14 [INFO]: Total sample number: 3997
2025-08-15 15:32:14 [INFO]: Training set size: 2557 (63.97%)
2025-08-15 15:32:14 [INFO]: Validation set size: 640 (16.01%)
2025-08-15 15:32:14 [INFO]: Test set size: 800 (20.02%)
2025-08-15 15:32:14 [INFO]: Number of steps: 48
2025-08-15 15:32:14 [INFO]: Number of features: 37
2025-08-15 15:32:14 [INFO]: Train set missing rate: 79.68%
2025-08-15 15:32:14 [INFO]: Validating set missing rate: 87.77%
2025-08-15 15:32:14 [INFO]: Test set missing rate: 87.98%
2025-08-15 15:32:14 [INFO]: Using the given device: cpu
2025-08-15 15:32:14 [INFO]: Model files will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:32:14 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:32:14 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:32:14 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:32:15 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 909,349
2025-08-15 15:32:16 [ERROR]: âŒ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'physionet_2012' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
ğŸš€ Starting GPT4TS training pipeline...
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 738, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 815, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
ğŸš€ gpt4ts | dataset=physionet_2012 | mr=0.5 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:32:35 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:32:35 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-15 15:32:35 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-15 15:32:35 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-15 15:32:35 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-15 15:32:41 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-15 15:32:41 [INFO]: 115521 values masked out in the val set as ground truth, take 49.89% of the original observed values
2025-08-15 15:32:41 [INFO]: 142704 values masked out in the test set as ground truth, take 50.08% of the original observed values
2025-08-15 15:32:41 [INFO]: Total sample number: 3997
2025-08-15 15:32:41 [INFO]: Training set size: 2557 (63.97%)
2025-08-15 15:32:41 [INFO]: Validation set size: 640 (16.01%)
2025-08-15 15:32:41 [INFO]: Test set size: 800 (20.02%)
2025-08-15 15:32:41 [INFO]: Number of steps: 48
2025-08-15 15:32:41 [INFO]: Number of features: 37
2025-08-15 15:32:41 [INFO]: Train set missing rate: 79.68%
2025-08-15 15:32:41 [INFO]: Validating set missing rate: 89.79%
2025-08-15 15:32:41 [INFO]: Test set missing rate: 89.99%
2025-08-15 15:32:41 [INFO]: Using the given device: cpu
2025-08-15 15:32:41 [INFO]: Model files will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:32:41 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/physionet_2012/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:32:41 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:32:41 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:32:41 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 909,349
2025-08-15 15:32:42 [ERROR]: âŒ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'physionet_2012' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
ğŸš€ Starting GPT4TS training pipeline...
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 738, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 815, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
ğŸš€ gpt4ts | dataset=ettm1 | mr=0.1 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:33:02 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:33:02 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:33:02 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:33:02 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:33:02 [INFO]: Loaded successfully!
2025-08-15 15:33:02 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:33:02 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:33:02 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:33:02 [INFO]: Total sample number: 725
2025-08-15 15:33:02 [INFO]: Training set size: 427 (58.90%)
2025-08-15 15:33:02 [INFO]: Validation set size: 153 (21.10%)
2025-08-15 15:33:02 [INFO]: Test set size: 145 (20.00%)
2025-08-15 15:33:02 [INFO]: Number of steps: 96
2025-08-15 15:33:02 [INFO]: Number of features: 7
2025-08-15 15:33:02 [INFO]: Train set missing rate: 10.00%
2025-08-15 15:33:02 [INFO]: Validating set missing rate: 10.02%
2025-08-15 15:33:02 [INFO]: Test set missing rate: 9.87%
2025-08-15 15:33:02 [INFO]: Using the given device: cpu
2025-08-15 15:33:02 [INFO]: Model files will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:33:02 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:33:02 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:33:02 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:33:03 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:33:30 [INFO]: Epoch 001 - training loss (MAE): 0.2871, validation MSE: 0.1363
2025-08-15 15:33:56 [INFO]: Epoch 002 - training loss (MAE): 0.1972, validation MSE: 0.0673
2025-08-15 15:34:25 [INFO]: Epoch 003 - training loss (MAE): 0.1771, validation MSE: 0.0591
2025-08-15 15:34:52 [INFO]: Epoch 004 - training loss (MAE): 0.1679, validation MSE: 0.0557
2025-08-15 15:35:18 [INFO]: Epoch 005 - training loss (MAE): 0.1628, validation MSE: 0.0550
2025-08-15 15:35:47 [INFO]: Epoch 006 - training loss (MAE): 0.1601, validation MSE: 0.0546
2025-08-15 15:36:13 [INFO]: Epoch 007 - training loss (MAE): 0.1586, validation MSE: 0.0526
2025-08-15 15:36:38 [INFO]: Epoch 008 - training loss (MAE): 0.1570, validation MSE: 0.0521
2025-08-15 15:37:06 [INFO]: Epoch 009 - training loss (MAE): 0.1560, validation MSE: 0.0474
2025-08-15 15:37:29 [INFO]: Epoch 010 - training loss (MAE): 0.1553, validation MSE: 0.0498
2025-08-15 15:37:29 [INFO]: Finished training. The best model is from epoch#9.
2025-08-15 15:37:29 [INFO]: Saved the model to output/imputation/gpt4ts/ettm1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'ettm1' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.1722| MSE: 0.0696| RMSE: 0.2639| MRE: 0.2030| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/ettm1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=ettm1 | mr=0.2 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:37:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:37:45 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:37:45 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:37:45 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:37:45 [INFO]: Loaded successfully!
2025-08-15 15:37:45 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:37:45 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:37:45 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:37:45 [INFO]: Total sample number: 725
2025-08-15 15:37:45 [INFO]: Training set size: 427 (58.90%)
2025-08-15 15:37:45 [INFO]: Validation set size: 153 (21.10%)
2025-08-15 15:37:45 [INFO]: Test set size: 145 (20.00%)
2025-08-15 15:37:45 [INFO]: Number of steps: 96
2025-08-15 15:37:45 [INFO]: Number of features: 7
2025-08-15 15:37:45 [INFO]: Train set missing rate: 20.03%
2025-08-15 15:37:45 [INFO]: Validating set missing rate: 19.99%
2025-08-15 15:37:45 [INFO]: Test set missing rate: 20.13%
2025-08-15 15:37:45 [INFO]: Using the given device: cpu
2025-08-15 15:37:45 [INFO]: Model files will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:37:45 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:37:45 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:37:45 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:37:45 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:38:07 [INFO]: Epoch 001 - training loss (MAE): 0.2966, validation MSE: 0.1362
2025-08-15 15:38:25 [INFO]: Epoch 002 - training loss (MAE): 0.2077, validation MSE: 0.0790
2025-08-15 15:38:45 [INFO]: Epoch 003 - training loss (MAE): 0.1885, validation MSE: 0.0689
2025-08-15 15:39:04 [INFO]: Epoch 004 - training loss (MAE): 0.1791, validation MSE: 0.0656
2025-08-15 15:39:24 [INFO]: Epoch 005 - training loss (MAE): 0.1734, validation MSE: 0.0620
2025-08-15 15:39:43 [INFO]: Epoch 006 - training loss (MAE): 0.1715, validation MSE: 0.0670
2025-08-15 15:39:59 [INFO]: Epoch 007 - training loss (MAE): 0.1714, validation MSE: 0.0594
2025-08-15 15:40:17 [INFO]: Epoch 008 - training loss (MAE): 0.1692, validation MSE: 0.0658
2025-08-15 15:40:33 [INFO]: Epoch 009 - training loss (MAE): 0.1689, validation MSE: 0.0584
2025-08-15 15:40:54 [INFO]: Epoch 010 - training loss (MAE): 0.1672, validation MSE: 0.0571
2025-08-15 15:40:54 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:40:54 [INFO]: Saved the model to output/imputation/gpt4ts/ettm1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'ettm1' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.1970| MSE: 0.0897| RMSE: 0.2995| MRE: 0.2329| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/ettm1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=ettm1 | mr=0.3 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:41:09 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:41:09 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:41:09 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:41:09 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:41:09 [INFO]: Loaded successfully!
2025-08-15 15:41:09 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:41:09 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:41:09 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:41:09 [INFO]: Total sample number: 725
2025-08-15 15:41:09 [INFO]: Training set size: 427 (58.90%)
2025-08-15 15:41:09 [INFO]: Validation set size: 153 (21.10%)
2025-08-15 15:41:09 [INFO]: Test set size: 145 (20.00%)
2025-08-15 15:41:09 [INFO]: Number of steps: 96
2025-08-15 15:41:09 [INFO]: Number of features: 7
2025-08-15 15:41:09 [INFO]: Train set missing rate: 30.13%
2025-08-15 15:41:09 [INFO]: Validating set missing rate: 29.97%
2025-08-15 15:41:09 [INFO]: Test set missing rate: 30.20%
2025-08-15 15:41:09 [INFO]: Using the given device: cpu
2025-08-15 15:41:09 [INFO]: Model files will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:41:09 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:41:09 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:41:09 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:41:09 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:41:29 [INFO]: Epoch 001 - training loss (MAE): 0.3046, validation MSE: 0.1481
2025-08-15 15:41:50 [INFO]: Epoch 002 - training loss (MAE): 0.2183, validation MSE: 0.0967
2025-08-15 15:42:09 [INFO]: Epoch 003 - training loss (MAE): 0.2005, validation MSE: 0.0792
2025-08-15 15:42:30 [INFO]: Epoch 004 - training loss (MAE): 0.1898, validation MSE: 0.0783
2025-08-15 15:42:51 [INFO]: Epoch 005 - training loss (MAE): 0.1854, validation MSE: 0.0757
2025-08-15 15:43:09 [INFO]: Epoch 006 - training loss (MAE): 0.1819, validation MSE: 0.0811
2025-08-15 15:43:29 [INFO]: Epoch 007 - training loss (MAE): 0.1844, validation MSE: 0.0705
2025-08-15 15:43:50 [INFO]: Epoch 008 - training loss (MAE): 0.1809, validation MSE: 0.0784
2025-08-15 15:44:11 [INFO]: Epoch 009 - training loss (MAE): 0.1809, validation MSE: 0.0695
2025-08-15 15:44:31 [INFO]: Epoch 010 - training loss (MAE): 0.1778, validation MSE: 0.0686
2025-08-15 15:44:31 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:44:31 [INFO]: Saved the model to output/imputation/gpt4ts/ettm1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'ettm1' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2117| MSE: 0.1030| RMSE: 0.3209| MRE: 0.2508| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/ettm1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=ettm1 | mr=0.4 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:44:46 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:44:46 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:44:46 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:44:46 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:44:46 [INFO]: Loaded successfully!
2025-08-15 15:44:46 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:44:46 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:44:46 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:44:46 [INFO]: Total sample number: 725
2025-08-15 15:44:46 [INFO]: Training set size: 427 (58.90%)
2025-08-15 15:44:46 [INFO]: Validation set size: 153 (21.10%)
2025-08-15 15:44:46 [INFO]: Test set size: 145 (20.00%)
2025-08-15 15:44:46 [INFO]: Number of steps: 96
2025-08-15 15:44:46 [INFO]: Number of features: 7
2025-08-15 15:44:46 [INFO]: Train set missing rate: 40.11%
2025-08-15 15:44:46 [INFO]: Validating set missing rate: 39.95%
2025-08-15 15:44:46 [INFO]: Test set missing rate: 39.98%
2025-08-15 15:44:46 [INFO]: Using the given device: cpu
2025-08-15 15:44:46 [INFO]: Model files will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:44:46 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:44:46 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:44:46 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:44:47 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:45:12 [INFO]: Epoch 001 - training loss (MAE): 0.3168, validation MSE: 0.1463
2025-08-15 15:45:34 [INFO]: Epoch 002 - training loss (MAE): 0.2291, validation MSE: 0.1108
2025-08-15 15:45:54 [INFO]: Epoch 003 - training loss (MAE): 0.2128, validation MSE: 0.0965
2025-08-15 15:46:17 [INFO]: Epoch 004 - training loss (MAE): 0.2038, validation MSE: 0.0889
2025-08-15 15:46:39 [INFO]: Epoch 005 - training loss (MAE): 0.1979, validation MSE: 0.0855
2025-08-15 15:46:59 [INFO]: Epoch 006 - training loss (MAE): 0.1945, validation MSE: 0.0897
2025-08-15 15:47:21 [INFO]: Epoch 007 - training loss (MAE): 0.1965, validation MSE: 0.0798
2025-08-15 15:47:43 [INFO]: Epoch 008 - training loss (MAE): 0.1920, validation MSE: 0.0848
2025-08-15 15:48:01 [INFO]: Epoch 009 - training loss (MAE): 0.1927, validation MSE: 0.0779
2025-08-15 15:48:24 [INFO]: Epoch 010 - training loss (MAE): 0.1908, validation MSE: 0.0785
2025-08-15 15:48:24 [INFO]: Finished training. The best model is from epoch#9.
2025-08-15 15:48:24 [INFO]: Saved the model to output/imputation/gpt4ts/ettm1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'ettm1' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2257| MSE: 0.1176| RMSE: 0.3429| MRE: 0.2672| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/ettm1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=ettm1 | mr=0.5 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:48:39 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:48:39 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:48:39 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:48:39 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:48:39 [INFO]: Loaded successfully!
2025-08-15 15:48:39 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:48:39 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:48:39 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:48:39 [INFO]: Total sample number: 725
2025-08-15 15:48:39 [INFO]: Training set size: 427 (58.90%)
2025-08-15 15:48:39 [INFO]: Validation set size: 153 (21.10%)
2025-08-15 15:48:39 [INFO]: Test set size: 145 (20.00%)
2025-08-15 15:48:39 [INFO]: Number of steps: 96
2025-08-15 15:48:39 [INFO]: Number of features: 7
2025-08-15 15:48:39 [INFO]: Train set missing rate: 50.15%
2025-08-15 15:48:39 [INFO]: Validating set missing rate: 49.83%
2025-08-15 15:48:39 [INFO]: Test set missing rate: 49.84%
2025-08-15 15:48:39 [INFO]: Using the given device: cpu
2025-08-15 15:48:39 [INFO]: Model files will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:48:39 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/ettm1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:48:39 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:48:39 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:48:40 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:48:59 [INFO]: Epoch 001 - training loss (MAE): 0.3296, validation MSE: 0.1633
2025-08-15 15:49:16 [INFO]: Epoch 002 - training loss (MAE): 0.2434, validation MSE: 0.1298
2025-08-15 15:49:39 [INFO]: Epoch 003 - training loss (MAE): 0.2274, validation MSE: 0.1151
2025-08-15 15:50:01 [INFO]: Epoch 004 - training loss (MAE): 0.2180, validation MSE: 0.1073
2025-08-15 15:50:21 [INFO]: Epoch 005 - training loss (MAE): 0.2123, validation MSE: 0.0971
2025-08-15 15:50:38 [INFO]: Epoch 006 - training loss (MAE): 0.2099, validation MSE: 0.1022
2025-08-15 15:50:59 [INFO]: Epoch 007 - training loss (MAE): 0.2128, validation MSE: 0.1015
2025-08-15 15:51:19 [INFO]: Epoch 008 - training loss (MAE): 0.2079, validation MSE: 0.1000
2025-08-15 15:51:37 [INFO]: Epoch 009 - training loss (MAE): 0.2074, validation MSE: 0.0912
2025-08-15 15:51:55 [INFO]: Epoch 010 - training loss (MAE): 0.2055, validation MSE: 0.0925
2025-08-15 15:51:55 [INFO]: Finished training. The best model is from epoch#9.
2025-08-15 15:51:55 [INFO]: Saved the model to output/imputation/gpt4ts/ettm1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'ettm1' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2444| MSE: 0.1368| RMSE: 0.3699| MRE: 0.2885| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/ettm1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=etth1 | mr=0.1 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:52:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:52:10 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:52:10 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:52:10 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:52:10 [INFO]: Loaded successfully!
2025-08-15 15:52:10 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:52:10 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:52:10 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:52:10 [INFO]: Total sample number: 180
2025-08-15 15:52:10 [INFO]: Training set size: 106 (58.89%)
2025-08-15 15:52:10 [INFO]: Validation set size: 38 (21.11%)
2025-08-15 15:52:10 [INFO]: Test set size: 36 (20.00%)
2025-08-15 15:52:10 [INFO]: Number of steps: 96
2025-08-15 15:52:10 [INFO]: Number of features: 7
2025-08-15 15:52:10 [INFO]: Train set missing rate: 9.86%
2025-08-15 15:52:10 [INFO]: Validating set missing rate: 9.84%
2025-08-15 15:52:10 [INFO]: Test set missing rate: 9.94%
2025-08-15 15:52:10 [INFO]: Using the given device: cpu
2025-08-15 15:52:10 [INFO]: Model files will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:52:10 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:52:10 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:52:10 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:52:11 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:52:18 [INFO]: Epoch 001 - training loss (MAE): 0.4232, validation MSE: 0.3462
2025-08-15 15:52:25 [INFO]: Epoch 002 - training loss (MAE): 0.3258, validation MSE: 0.1651
2025-08-15 15:52:30 [INFO]: Epoch 003 - training loss (MAE): 0.2964, validation MSE: 0.1369
2025-08-15 15:52:36 [INFO]: Epoch 004 - training loss (MAE): 0.2653, validation MSE: 0.1524
2025-08-15 15:52:41 [INFO]: Epoch 005 - training loss (MAE): 0.2593, validation MSE: 0.1269
2025-08-15 15:52:46 [INFO]: Epoch 006 - training loss (MAE): 0.2392, validation MSE: 0.1129
2025-08-15 15:52:50 [INFO]: Epoch 007 - training loss (MAE): 0.2328, validation MSE: 0.0969
2025-08-15 15:52:56 [INFO]: Epoch 008 - training loss (MAE): 0.2295, validation MSE: 0.0892
2025-08-15 15:53:00 [INFO]: Epoch 009 - training loss (MAE): 0.2281, validation MSE: 0.0981
2025-08-15 15:53:04 [INFO]: Epoch 010 - training loss (MAE): 0.2241, validation MSE: 0.0865
2025-08-15 15:53:04 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:53:04 [INFO]: Saved the model to output/imputation/gpt4ts/etth1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'etth1' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2335| MSE: 0.1148| RMSE: 0.3388| MRE: 0.2825| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/etth1/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=etth1 | mr=0.2 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:53:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:53:17 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:53:17 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:53:17 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:53:17 [INFO]: Loaded successfully!
2025-08-15 15:53:17 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:53:17 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:53:17 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:53:17 [INFO]: Total sample number: 180
2025-08-15 15:53:17 [INFO]: Training set size: 106 (58.89%)
2025-08-15 15:53:17 [INFO]: Validation set size: 38 (21.11%)
2025-08-15 15:53:17 [INFO]: Test set size: 36 (20.00%)
2025-08-15 15:53:17 [INFO]: Number of steps: 96
2025-08-15 15:53:17 [INFO]: Number of features: 7
2025-08-15 15:53:17 [INFO]: Train set missing rate: 19.76%
2025-08-15 15:53:17 [INFO]: Validating set missing rate: 19.91%
2025-08-15 15:53:17 [INFO]: Test set missing rate: 19.98%
2025-08-15 15:53:17 [INFO]: Using the given device: cpu
2025-08-15 15:53:17 [INFO]: Model files will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:53:17 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:53:17 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:53:17 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:53:17 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:53:24 [INFO]: Epoch 001 - training loss (MAE): 0.4275, validation MSE: 0.3659
2025-08-15 15:53:30 [INFO]: Epoch 002 - training loss (MAE): 0.3371, validation MSE: 0.1921
2025-08-15 15:53:36 [INFO]: Epoch 003 - training loss (MAE): 0.3113, validation MSE: 0.1586
2025-08-15 15:53:41 [INFO]: Epoch 004 - training loss (MAE): 0.2781, validation MSE: 0.1574
2025-08-15 15:53:47 [INFO]: Epoch 005 - training loss (MAE): 0.2712, validation MSE: 0.1367
2025-08-15 15:53:52 [INFO]: Epoch 006 - training loss (MAE): 0.2501, validation MSE: 0.1236
2025-08-15 15:53:58 [INFO]: Epoch 007 - training loss (MAE): 0.2451, validation MSE: 0.1105
2025-08-15 15:54:04 [INFO]: Epoch 008 - training loss (MAE): 0.2400, validation MSE: 0.1008
2025-08-15 15:54:11 [INFO]: Epoch 009 - training loss (MAE): 0.2400, validation MSE: 0.1025
2025-08-15 15:54:17 [INFO]: Epoch 010 - training loss (MAE): 0.2397, validation MSE: 0.0937
2025-08-15 15:54:18 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:54:18 [INFO]: Saved the model to output/imputation/gpt4ts/etth1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'etth1' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2578| MSE: 0.1384| RMSE: 0.3721| MRE: 0.3098| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/etth1/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=etth1 | mr=0.3 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:54:29 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:54:29 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:54:29 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:54:29 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:54:29 [INFO]: Loaded successfully!
2025-08-15 15:54:29 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:54:29 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:54:29 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:54:29 [INFO]: Total sample number: 180
2025-08-15 15:54:29 [INFO]: Training set size: 106 (58.89%)
2025-08-15 15:54:29 [INFO]: Validation set size: 38 (21.11%)
2025-08-15 15:54:29 [INFO]: Test set size: 36 (20.00%)
2025-08-15 15:54:29 [INFO]: Number of steps: 96
2025-08-15 15:54:29 [INFO]: Number of features: 7
2025-08-15 15:54:29 [INFO]: Train set missing rate: 29.75%
2025-08-15 15:54:29 [INFO]: Validating set missing rate: 29.99%
2025-08-15 15:54:29 [INFO]: Test set missing rate: 30.17%
2025-08-15 15:54:29 [INFO]: Using the given device: cpu
2025-08-15 15:54:29 [INFO]: Model files will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:54:29 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:54:29 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:54:29 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:54:30 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:54:39 [INFO]: Epoch 001 - training loss (MAE): 0.4347, validation MSE: 0.3908
2025-08-15 15:54:45 [INFO]: Epoch 002 - training loss (MAE): 0.3523, validation MSE: 0.2232
2025-08-15 15:54:52 [INFO]: Epoch 003 - training loss (MAE): 0.3238, validation MSE: 0.1863
2025-08-15 15:54:58 [INFO]: Epoch 004 - training loss (MAE): 0.2908, validation MSE: 0.1731
2025-08-15 15:55:04 [INFO]: Epoch 005 - training loss (MAE): 0.2846, validation MSE: 0.1517
2025-08-15 15:55:09 [INFO]: Epoch 006 - training loss (MAE): 0.2638, validation MSE: 0.1436
2025-08-15 15:55:15 [INFO]: Epoch 007 - training loss (MAE): 0.2617, validation MSE: 0.1342
2025-08-15 15:55:21 [INFO]: Epoch 008 - training loss (MAE): 0.2549, validation MSE: 0.1254
2025-08-15 15:55:28 [INFO]: Epoch 009 - training loss (MAE): 0.2559, validation MSE: 0.1286
2025-08-15 15:55:33 [INFO]: Epoch 010 - training loss (MAE): 0.2561, validation MSE: 0.1168
2025-08-15 15:55:33 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:55:34 [INFO]: Saved the model to output/imputation/gpt4ts/etth1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'etth1' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2759| MSE: 0.1637| RMSE: 0.4046| MRE: 0.3262| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/etth1/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=etth1 | mr=0.4 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:55:43 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:55:43 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:55:43 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:55:43 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:55:43 [INFO]: Loaded successfully!
2025-08-15 15:55:43 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:55:43 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:55:43 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:55:43 [INFO]: Total sample number: 180
2025-08-15 15:55:43 [INFO]: Training set size: 106 (58.89%)
2025-08-15 15:55:43 [INFO]: Validation set size: 38 (21.11%)
2025-08-15 15:55:43 [INFO]: Test set size: 36 (20.00%)
2025-08-15 15:55:43 [INFO]: Number of steps: 96
2025-08-15 15:55:43 [INFO]: Number of features: 7
2025-08-15 15:55:43 [INFO]: Train set missing rate: 39.82%
2025-08-15 15:55:43 [INFO]: Validating set missing rate: 39.92%
2025-08-15 15:55:43 [INFO]: Test set missing rate: 40.57%
2025-08-15 15:55:43 [INFO]: Using the given device: cpu
2025-08-15 15:55:43 [INFO]: Model files will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:55:43 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:55:43 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:55:43 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:55:44 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:55:52 [INFO]: Epoch 001 - training loss (MAE): 0.4413, validation MSE: 0.3970
2025-08-15 15:56:00 [INFO]: Epoch 002 - training loss (MAE): 0.3690, validation MSE: 0.2494
2025-08-15 15:56:06 [INFO]: Epoch 003 - training loss (MAE): 0.3351, validation MSE: 0.2066
2025-08-15 15:56:13 [INFO]: Epoch 004 - training loss (MAE): 0.3046, validation MSE: 0.1867
2025-08-15 15:56:20 [INFO]: Epoch 005 - training loss (MAE): 0.2981, validation MSE: 0.1685
2025-08-15 15:56:26 [INFO]: Epoch 006 - training loss (MAE): 0.2790, validation MSE: 0.1641
2025-08-15 15:56:33 [INFO]: Epoch 007 - training loss (MAE): 0.2765, validation MSE: 0.1524
2025-08-15 15:56:39 [INFO]: Epoch 008 - training loss (MAE): 0.2713, validation MSE: 0.1408
2025-08-15 15:56:46 [INFO]: Epoch 009 - training loss (MAE): 0.2696, validation MSE: 0.1401
2025-08-15 15:56:53 [INFO]: Epoch 010 - training loss (MAE): 0.2712, validation MSE: 0.1320
2025-08-15 15:56:54 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:56:54 [INFO]: Saved the model to output/imputation/gpt4ts/etth1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'etth1' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2976| MSE: 0.1931| RMSE: 0.4394| MRE: 0.3511| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/etth1/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=etth1 | mr=0.5 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:57:04 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:57:04 [INFO]: You're using dataset electricity_transformer_temperature, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/electricity_transformer_temperature
2025-08-15 15:57:04 [INFO]: Dataset electricity_transformer_temperature has already been downloaded. Processing directly...
2025-08-15 15:57:04 [INFO]: Dataset electricity_transformer_temperature has already been cached. Loading from cache directly...
2025-08-15 15:57:04 [INFO]: Loaded successfully!
2025-08-15 15:57:04 [INFO]: months selected as train set are <PeriodArray>
['2016-07', '2016-08', '2016-09', '2016-10', '2016-11', '2016-12', '2017-01',
 '2017-02', '2017-03', '2017-04', '2017-05', '2017-06', '2017-07', '2017-08']
Length: 14, dtype: period[M]
2025-08-15 15:57:04 [INFO]: months selected as val set are <PeriodArray>
['2017-09', '2017-10', '2017-11', '2017-12', '2018-01']
Length: 5, dtype: period[M]
2025-08-15 15:57:04 [INFO]: months selected as test set are <PeriodArray>
['2018-02', '2018-03', '2018-04', '2018-05', '2018-06']
Length: 5, dtype: period[M]
2025-08-15 15:57:04 [INFO]: Total sample number: 180
2025-08-15 15:57:04 [INFO]: Training set size: 106 (58.89%)
2025-08-15 15:57:04 [INFO]: Validation set size: 38 (21.11%)
2025-08-15 15:57:04 [INFO]: Test set size: 36 (20.00%)
2025-08-15 15:57:04 [INFO]: Number of steps: 96
2025-08-15 15:57:04 [INFO]: Number of features: 7
2025-08-15 15:57:04 [INFO]: Train set missing rate: 50.08%
2025-08-15 15:57:04 [INFO]: Validating set missing rate: 50.08%
2025-08-15 15:57:04 [INFO]: Test set missing rate: 50.20%
2025-08-15 15:57:04 [INFO]: Using the given device: cpu
2025-08-15 15:57:04 [INFO]: Model files will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:57:04 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/etth1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:57:04 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:57:04 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:57:04 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 817,159
2025-08-15 15:57:12 [INFO]: Epoch 001 - training loss (MAE): 0.4486, validation MSE: 0.4342
2025-08-15 15:57:19 [INFO]: Epoch 002 - training loss (MAE): 0.3851, validation MSE: 0.2890
2025-08-15 15:57:24 [INFO]: Epoch 003 - training loss (MAE): 0.3624, validation MSE: 0.2358
2025-08-15 15:57:30 [INFO]: Epoch 004 - training loss (MAE): 0.3270, validation MSE: 0.2173
2025-08-15 15:57:37 [INFO]: Epoch 005 - training loss (MAE): 0.3212, validation MSE: 0.1888
2025-08-15 15:57:42 [INFO]: Epoch 006 - training loss (MAE): 0.3010, validation MSE: 0.1859
2025-08-15 15:57:49 [INFO]: Epoch 007 - training loss (MAE): 0.2971, validation MSE: 0.1907
2025-08-15 15:57:55 [INFO]: Epoch 008 - training loss (MAE): 0.2924, validation MSE: 0.1640
2025-08-15 15:58:00 [INFO]: Epoch 009 - training loss (MAE): 0.2882, validation MSE: 0.1590
2025-08-15 15:58:05 [INFO]: Epoch 010 - training loss (MAE): 0.2883, validation MSE: 0.1583
2025-08-15 15:58:05 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:58:05 [INFO]: Saved the model to output/imputation/gpt4ts/etth1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'etth1' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.3243| MSE: 0.2286| RMSE: 0.4782| MRE: 0.3835| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/etth1/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=italy_air_quality | mr=0.1 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:58:15 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:58:15 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-15 15:58:15 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-15 15:58:15 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-15 15:58:15 [INFO]: Loaded successfully!
2025-08-15 15:58:15 [INFO]: Total sample number: 192
2025-08-15 15:58:15 [INFO]: Training set size: 116 (60.42%)
2025-08-15 15:58:15 [INFO]: Validation set size: 38 (19.79%)
2025-08-15 15:58:15 [INFO]: Test set size: 38 (19.79%)
2025-08-15 15:58:15 [INFO]: Number of steps: 48
2025-08-15 15:58:15 [INFO]: Number of features: 13
2025-08-15 15:58:15 [INFO]: Train set missing rate: 9.87%
2025-08-15 15:58:15 [INFO]: Validating set missing rate: 9.86%
2025-08-15 15:58:15 [INFO]: Test set missing rate: 9.87%
2025-08-15 15:58:15 [INFO]: Using the given device: cpu
2025-08-15 15:58:15 [INFO]: Model files will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:58:15 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:58:15 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:58:15 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:58:15 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 835,597
2025-08-15 15:58:22 [INFO]: Epoch 001 - training loss (MAE): 0.4431, validation MSE: 0.5097
2025-08-15 15:58:27 [INFO]: Epoch 002 - training loss (MAE): 0.3390, validation MSE: 0.3928
2025-08-15 15:58:33 [INFO]: Epoch 003 - training loss (MAE): 0.2871, validation MSE: 0.3907
2025-08-15 15:58:38 [INFO]: Epoch 004 - training loss (MAE): 0.2719, validation MSE: 0.3885
2025-08-15 15:58:42 [INFO]: Epoch 005 - training loss (MAE): 0.2516, validation MSE: 0.3377
2025-08-15 15:58:44 [INFO]: Epoch 006 - training loss (MAE): 0.2309, validation MSE: 0.2791
2025-08-15 15:58:49 [INFO]: Epoch 007 - training loss (MAE): 0.2266, validation MSE: 0.2640
2025-08-15 15:58:52 [INFO]: Epoch 008 - training loss (MAE): 0.2265, validation MSE: 0.2608
2025-08-15 15:58:57 [INFO]: Epoch 009 - training loss (MAE): 0.2106, validation MSE: 0.2392
2025-08-15 15:59:01 [INFO]: Epoch 010 - training loss (MAE): 0.2079, validation MSE: 0.2377
2025-08-15 15:59:01 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 15:59:01 [INFO]: Saved the model to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'italy_air_quality' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.1826| MSE: 0.1235| RMSE: 0.3514| MRE: 0.2376| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.1_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=italy_air_quality | mr=0.2 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 15:59:09 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 15:59:09 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-15 15:59:09 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-15 15:59:09 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-15 15:59:09 [INFO]: Loaded successfully!
2025-08-15 15:59:09 [INFO]: Total sample number: 192
2025-08-15 15:59:09 [INFO]: Training set size: 116 (60.42%)
2025-08-15 15:59:09 [INFO]: Validation set size: 38 (19.79%)
2025-08-15 15:59:09 [INFO]: Test set size: 38 (19.79%)
2025-08-15 15:59:09 [INFO]: Number of steps: 48
2025-08-15 15:59:09 [INFO]: Number of features: 13
2025-08-15 15:59:09 [INFO]: Train set missing rate: 19.79%
2025-08-15 15:59:09 [INFO]: Validating set missing rate: 19.86%
2025-08-15 15:59:09 [INFO]: Test set missing rate: 19.88%
2025-08-15 15:59:09 [INFO]: Using the given device: cpu
2025-08-15 15:59:09 [INFO]: Model files will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 15:59:09 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 15:59:09 [INFO]: Using customized MAE as the training loss function.
2025-08-15 15:59:09 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 15:59:10 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 835,597
2025-08-15 15:59:15 [INFO]: Epoch 001 - training loss (MAE): 0.4422, validation MSE: 0.5532
2025-08-15 15:59:20 [INFO]: Epoch 002 - training loss (MAE): 0.3457, validation MSE: 0.4132
2025-08-15 15:59:24 [INFO]: Epoch 003 - training loss (MAE): 0.2913, validation MSE: 0.4080
2025-08-15 15:59:29 [INFO]: Epoch 004 - training loss (MAE): 0.2772, validation MSE: 0.4063
2025-08-15 15:59:35 [INFO]: Epoch 005 - training loss (MAE): 0.2579, validation MSE: 0.3565
2025-08-15 15:59:39 [INFO]: Epoch 006 - training loss (MAE): 0.2401, validation MSE: 0.2999
2025-08-15 15:59:45 [INFO]: Epoch 007 - training loss (MAE): 0.2321, validation MSE: 0.2834
2025-08-15 15:59:49 [INFO]: Epoch 008 - training loss (MAE): 0.2359, validation MSE: 0.2713
2025-08-15 15:59:54 [INFO]: Epoch 009 - training loss (MAE): 0.2199, validation MSE: 0.2590
2025-08-15 15:59:59 [INFO]: Epoch 010 - training loss (MAE): 0.2203, validation MSE: 0.2638
2025-08-15 15:59:59 [INFO]: Finished training. The best model is from epoch#9.
2025-08-15 16:00:00 [INFO]: Saved the model to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'italy_air_quality' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.1918| MSE: 0.1387| RMSE: 0.3724| MRE: 0.2475| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.2_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=italy_air_quality | mr=0.3 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 16:00:07 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 16:00:07 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-15 16:00:07 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-15 16:00:07 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-15 16:00:07 [INFO]: Loaded successfully!
2025-08-15 16:00:07 [INFO]: Total sample number: 192
2025-08-15 16:00:07 [INFO]: Training set size: 116 (60.42%)
2025-08-15 16:00:07 [INFO]: Validation set size: 38 (19.79%)
2025-08-15 16:00:07 [INFO]: Test set size: 38 (19.79%)
2025-08-15 16:00:07 [INFO]: Number of steps: 48
2025-08-15 16:00:07 [INFO]: Number of features: 13
2025-08-15 16:00:07 [INFO]: Train set missing rate: 29.80%
2025-08-15 16:00:07 [INFO]: Validating set missing rate: 29.90%
2025-08-15 16:00:07 [INFO]: Test set missing rate: 30.05%
2025-08-15 16:00:07 [INFO]: Using the given device: cpu
2025-08-15 16:00:07 [INFO]: Model files will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 16:00:07 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 16:00:07 [INFO]: Using customized MAE as the training loss function.
2025-08-15 16:00:07 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 16:00:08 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 835,597
2025-08-15 16:00:14 [INFO]: Epoch 001 - training loss (MAE): 0.4436, validation MSE: 0.5796
2025-08-15 16:00:20 [INFO]: Epoch 002 - training loss (MAE): 0.3552, validation MSE: 0.4237
2025-08-15 16:00:29 [INFO]: Epoch 003 - training loss (MAE): 0.3042, validation MSE: 0.3985
2025-08-15 16:00:40 [INFO]: Epoch 004 - training loss (MAE): 0.2797, validation MSE: 0.4066
2025-08-15 16:00:50 [INFO]: Epoch 005 - training loss (MAE): 0.2686, validation MSE: 0.3828
2025-08-15 16:01:00 [INFO]: Epoch 006 - training loss (MAE): 0.2485, validation MSE: 0.3365
2025-08-15 16:01:10 [INFO]: Epoch 007 - training loss (MAE): 0.2433, validation MSE: 0.3081
2025-08-15 16:01:22 [INFO]: Epoch 008 - training loss (MAE): 0.2454, validation MSE: 0.2996
2025-08-15 16:01:33 [INFO]: Epoch 009 - training loss (MAE): 0.2289, validation MSE: 0.2821
2025-08-15 16:01:43 [INFO]: Epoch 010 - training loss (MAE): 0.2291, validation MSE: 0.2783
2025-08-15 16:01:43 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 16:01:44 [INFO]: Saved the model to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'italy_air_quality' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2041| MSE: 0.1665| RMSE: 0.4081| MRE: 0.2611| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.3_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=italy_air_quality | mr=0.4 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 16:02:03 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 16:02:03 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-15 16:02:03 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-15 16:02:03 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-15 16:02:03 [INFO]: Loaded successfully!
2025-08-15 16:02:03 [INFO]: Total sample number: 192
2025-08-15 16:02:03 [INFO]: Training set size: 116 (60.42%)
2025-08-15 16:02:03 [INFO]: Validation set size: 38 (19.79%)
2025-08-15 16:02:03 [INFO]: Test set size: 38 (19.79%)
2025-08-15 16:02:03 [INFO]: Number of steps: 48
2025-08-15 16:02:03 [INFO]: Number of features: 13
2025-08-15 16:02:03 [INFO]: Train set missing rate: 39.84%
2025-08-15 16:02:03 [INFO]: Validating set missing rate: 39.87%
2025-08-15 16:02:03 [INFO]: Test set missing rate: 40.52%
2025-08-15 16:02:03 [INFO]: Using the given device: cpu
2025-08-15 16:02:03 [INFO]: Model files will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 16:02:03 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 16:02:03 [INFO]: Using customized MAE as the training loss function.
2025-08-15 16:02:03 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 16:02:04 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 835,597
2025-08-15 16:02:16 [INFO]: Epoch 001 - training loss (MAE): 0.4492, validation MSE: 0.6344
2025-08-15 16:02:26 [INFO]: Epoch 002 - training loss (MAE): 0.3729, validation MSE: 0.4435
2025-08-15 16:02:35 [INFO]: Epoch 003 - training loss (MAE): 0.3199, validation MSE: 0.3806
2025-08-15 16:02:47 [INFO]: Epoch 004 - training loss (MAE): 0.2899, validation MSE: 0.3874
2025-08-15 16:02:56 [INFO]: Epoch 005 - training loss (MAE): 0.2814, validation MSE: 0.3865
2025-08-15 16:03:07 [INFO]: Epoch 006 - training loss (MAE): 0.2675, validation MSE: 0.3363
2025-08-15 16:03:17 [INFO]: Epoch 007 - training loss (MAE): 0.2650, validation MSE: 0.3117
2025-08-15 16:03:28 [INFO]: Epoch 008 - training loss (MAE): 0.2572, validation MSE: 0.2996
2025-08-15 16:03:39 [INFO]: Epoch 009 - training loss (MAE): 0.2460, validation MSE: 0.2832
2025-08-15 16:03:51 [INFO]: Epoch 010 - training loss (MAE): 0.2429, validation MSE: 0.2746
2025-08-15 16:03:51 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 16:03:52 [INFO]: Saved the model to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'italy_air_quality' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2106| MSE: 0.1801| RMSE: 0.4244| MRE: 0.2704| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.4_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
ğŸš€ gpt4ts | dataset=italy_air_quality | mr=0.5 | bs=32 | d_model=64 | d_ffn=128 | heads=4 | layers=2 | llm=openai-community/gpt2 | profiling=true
2025-08-15 16:04:08 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-15 16:04:08 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-15 16:04:08 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-15 16:04:08 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-15 16:04:08 [INFO]: Loaded successfully!
2025-08-15 16:04:08 [INFO]: Total sample number: 192
2025-08-15 16:04:08 [INFO]: Training set size: 116 (60.42%)
2025-08-15 16:04:08 [INFO]: Validation set size: 38 (19.79%)
2025-08-15 16:04:08 [INFO]: Test set size: 38 (19.79%)
2025-08-15 16:04:08 [INFO]: Number of steps: 48
2025-08-15 16:04:08 [INFO]: Number of features: 13
2025-08-15 16:04:08 [INFO]: Train set missing rate: 50.11%
2025-08-15 16:04:08 [INFO]: Validating set missing rate: 50.03%
2025-08-15 16:04:08 [INFO]: Test set missing rate: 50.12%
2025-08-15 16:04:08 [INFO]: Using the given device: cpu
2025-08-15 16:04:08 [INFO]: Model files will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue
2025-08-15 16:04:08 [INFO]: Tensorboard file will be saved to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/tensorboard
2025-08-15 16:04:08 [INFO]: Using customized MAE as the training loss function.
2025-08-15 16:04:08 [INFO]: Using customized MSE as the validation metric function.
2025-08-15 16:04:09 [INFO]: GPT4TS initialized with the given hyperparameters, the number of trainable parameters: 835,597
2025-08-15 16:04:15 [INFO]: Epoch 001 - training loss (MAE): 0.4490, validation MSE: 0.6814
2025-08-15 16:04:22 [INFO]: Epoch 002 - training loss (MAE): 0.3911, validation MSE: 0.4988
2025-08-15 16:04:26 [INFO]: Epoch 003 - training loss (MAE): 0.3389, validation MSE: 0.4126
2025-08-15 16:04:32 [INFO]: Epoch 004 - training loss (MAE): 0.3052, validation MSE: 0.3950
2025-08-15 16:04:37 [INFO]: Epoch 005 - training loss (MAE): 0.2924, validation MSE: 0.4026
2025-08-15 16:04:41 [INFO]: Epoch 006 - training loss (MAE): 0.2789, validation MSE: 0.3752
2025-08-15 16:04:47 [INFO]: Epoch 007 - training loss (MAE): 0.2805, validation MSE: 0.3490
2025-08-15 16:04:52 [INFO]: Epoch 008 - training loss (MAE): 0.2756, validation MSE: 0.3408
2025-08-15 16:04:59 [INFO]: Epoch 009 - training loss (MAE): 0.2617, validation MSE: 0.3102
2025-08-15 16:05:02 [INFO]: Epoch 010 - training loss (MAE): 0.2616, validation MSE: 0.2957
2025-08-15 16:05:02 [INFO]: Finished training. The best model is from epoch#10.
2025-08-15 16:05:02 [INFO]: Saved the model to output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/GPT4TS.pypots
[34m
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘
   â•šâ•â•   â•šâ•â•â•šâ•â•     â•šâ•â•â•šâ•â•â•â•â•â•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
ğŸš€ Running imputation pipeline for model: gpt4ts
â„¹ï¸ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
âœ… Dataset 'italy_air_quality' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
ğŸš€ Starting GPT4TS training pipeline...
[GPT4TS] Testing â€”â€” MAE: 0.2228| MSE: 0.1996| RMSE: 0.4468| MRE: 0.2870| 
ğŸ“Š Metrics saved to: output/imputation/gpt4ts/italy_air_quality/epoch10/mr0.5_bs32_dm64_ffn128_h4_ly2_proftrue/metrics/gpt4ts_metrics.json
âœ… All gpt4ts runs completed.
