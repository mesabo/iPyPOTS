ai-gpgpu14
Visible GPUs: 0,1,2,3,4,5,6,7
Using devices: cuda:6
Session log: output/imputation/cuda:6/session_gpt4ts_20250823T102506.log
🔥 RUN: gpt4ts | physionet_2012 | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=35)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:25:44 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:25:44 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-23 10:25:44 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-23 10:25:44 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-23 10:25:44 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-23 10:25:53 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-23 10:25:53 [INFO]: 22947 values masked out in the val set as ground truth, take 9.91% of the original observed values
2025-08-23 10:25:53 [INFO]: 28724 values masked out in the test set as ground truth, take 10.08% of the original observed values
2025-08-23 10:25:53 [INFO]: Total sample number: 3997
2025-08-23 10:25:53 [INFO]: Training set size: 2557 (63.97%)
2025-08-23 10:25:53 [INFO]: Validation set size: 640 (16.01%)
2025-08-23 10:25:53 [INFO]: Test set size: 800 (20.02%)
2025-08-23 10:25:53 [INFO]: Number of steps: 48
2025-08-23 10:25:53 [INFO]: Number of features: 37
2025-08-23 10:25:53 [INFO]: Train set missing rate: 79.68%
2025-08-23 10:25:53 [INFO]: Validating set missing rate: 81.65%
2025-08-23 10:25:53 [INFO]: Test set missing rate: 81.96%
✅ Dataset 'physionet_2012' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:25:53 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:25:53 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:25:53 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:25:53 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:25:53 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:25:53 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:25:55 [INFO]: Model placed on cuda:6
2025-08-23 10:25:55 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,646,821
 ├─ Trainable parameters: 906,277
 └─ Trainable ratio: 1.94%
2025-08-23 10:25:55 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): physionet_2012 | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | physionet_2012 | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=35)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:26:19 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:26:19 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-23 10:26:19 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-23 10:26:19 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-23 10:26:19 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-23 10:26:32 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-23 10:26:32 [INFO]: 46041 values masked out in the val set as ground truth, take 19.88% of the original observed values
2025-08-23 10:26:32 [INFO]: 57450 values masked out in the test set as ground truth, take 20.16% of the original observed values
2025-08-23 10:26:32 [INFO]: Total sample number: 3997
2025-08-23 10:26:32 [INFO]: Training set size: 2557 (63.97%)
2025-08-23 10:26:32 [INFO]: Validation set size: 640 (16.01%)
2025-08-23 10:26:32 [INFO]: Test set size: 800 (20.02%)
2025-08-23 10:26:32 [INFO]: Number of steps: 48
2025-08-23 10:26:32 [INFO]: Number of features: 37
✅ Dataset 'physionet_2012' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:26:32 [INFO]: Train set missing rate: 79.68%
2025-08-23 10:26:32 [INFO]: Validating set missing rate: 83.68%
2025-08-23 10:26:32 [INFO]: Test set missing rate: 83.99%
2025-08-23 10:26:32 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:26:32 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:26:32 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:26:32 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:26:32 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:26:32 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:26:34 [INFO]: Model placed on cuda:6
2025-08-23 10:26:34 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,646,821
 ├─ Trainable parameters: 906,277
 └─ Trainable ratio: 1.94%
2025-08-23 10:26:34 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): physionet_2012 | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | physionet_2012 | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=35)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:26:42 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:26:42 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-23 10:26:42 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-23 10:26:42 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-23 10:26:42 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-23 10:26:48 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-23 10:26:48 [INFO]: 69227 values masked out in the val set as ground truth, take 29.90% of the original observed values
2025-08-23 10:26:48 [INFO]: 85805 values masked out in the test set as ground truth, take 30.11% of the original observed values
2025-08-23 10:26:48 [INFO]: Total sample number: 3997
2025-08-23 10:26:48 [INFO]: Training set size: 2557 (63.97%)
2025-08-23 10:26:48 [INFO]: Validation set size: 640 (16.01%)
2025-08-23 10:26:48 [INFO]: Test set size: 800 (20.02%)
2025-08-23 10:26:48 [INFO]: Number of steps: 48
2025-08-23 10:26:48 [INFO]: Number of features: 37
2025-08-23 10:26:48 [INFO]: Train set missing rate: 79.68%
2025-08-23 10:26:48 [INFO]: Validating set missing rate: 85.72%
2025-08-23 10:26:48 [INFO]: Test set missing rate: 85.98%
✅ Dataset 'physionet_2012' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:26:48 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:26:48 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:26:49 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:26:49 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:26:49 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:26:49 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:26:50 [INFO]: Model placed on cuda:6
2025-08-23 10:26:50 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,646,821
 ├─ Trainable parameters: 906,277
 └─ Trainable ratio: 1.94%
2025-08-23 10:26:51 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): physionet_2012 | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | physionet_2012 | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=35)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:27:16 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:27:16 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-23 10:27:16 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-23 10:27:16 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-23 10:27:16 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-23 10:27:27 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-23 10:27:27 [INFO]: 92507 values masked out in the val set as ground truth, take 39.95% of the original observed values
2025-08-23 10:27:27 [INFO]: 114242 values masked out in the test set as ground truth, take 40.09% of the original observed values
2025-08-23 10:27:27 [INFO]: Total sample number: 3997
2025-08-23 10:27:27 [INFO]: Training set size: 2557 (63.97%)
2025-08-23 10:27:27 [INFO]: Validation set size: 640 (16.01%)
2025-08-23 10:27:27 [INFO]: Test set size: 800 (20.02%)
2025-08-23 10:27:27 [INFO]: Number of steps: 48
2025-08-23 10:27:27 [INFO]: Number of features: 37
2025-08-23 10:27:27 [INFO]: Train set missing rate: 79.68%
2025-08-23 10:27:27 [INFO]: Validating set missing rate: 87.77%
2025-08-23 10:27:27 [INFO]: Test set missing rate: 87.98%
✅ Dataset 'physionet_2012' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:27:27 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:27:27 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:27:28 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:27:28 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:27:28 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:27:28 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:27:29 [INFO]: Model placed on cuda:6
2025-08-23 10:27:29 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,646,821
 ├─ Trainable parameters: 906,277
 └─ Trainable ratio: 1.94%
2025-08-23 10:27:31 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): physionet_2012 | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | physionet_2012 | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=35)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:27:51 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:27:51 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012
2025-08-23 10:27:51 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...
2025-08-23 10:27:51 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...
2025-08-23 10:27:51 [INFO]: Loaded successfully!
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/physionet_2012.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.
  X = X.groupby("RecordID").apply(apply_func)
2025-08-23 10:28:02 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. 
2025-08-23 10:28:02 [INFO]: 115521 values masked out in the val set as ground truth, take 49.89% of the original observed values
2025-08-23 10:28:02 [INFO]: 142704 values masked out in the test set as ground truth, take 50.08% of the original observed values
2025-08-23 10:28:02 [INFO]: Total sample number: 3997
2025-08-23 10:28:02 [INFO]: Training set size: 2557 (63.97%)
2025-08-23 10:28:02 [INFO]: Validation set size: 640 (16.01%)
2025-08-23 10:28:02 [INFO]: Test set size: 800 (20.02%)
2025-08-23 10:28:02 [INFO]: Number of steps: 48
2025-08-23 10:28:02 [INFO]: Number of features: 37
2025-08-23 10:28:02 [INFO]: Train set missing rate: 79.68%
2025-08-23 10:28:02 [INFO]: Validating set missing rate: 89.79%
2025-08-23 10:28:02 [INFO]: Test set missing rate: 89.99%
✅ Dataset 'physionet_2012' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:28:02 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:28:02 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:28:04 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:28:04 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/physionet_2012/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:28:04 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:28:04 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:28:06 [INFO]: Model placed on cuda:6
2025-08-23 10:28:06 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,646,821
 ├─ Trainable parameters: 906,277
 └─ Trainable ratio: 1.94%
2025-08-23 10:28:07 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): physionet_2012 | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | beijing_multisite_air_quality | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:28:27 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:28:27 [INFO]: You're using dataset beijing_multisite_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/beijing_multisite_air_quality
2025-08-23 10:28:27 [INFO]: Dataset beijing_multisite_air_quality has already been downloaded. Processing directly...
2025-08-23 10:28:27 [INFO]: Dataset beijing_multisite_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:28:27 [INFO]: Loaded successfully!
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:27 [INFO]: There are total 12 stations, they are ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']
2025-08-23 10:28:27 [INFO]: Original df missing rate: 0.016
2025-08-23 10:28:27 [INFO]: months selected as train set are <PeriodArray>
['2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09',
 '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04',
 '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11',
 '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06']
Length: 28, dtype: period[M]
2025-08-23 10:28:27 [INFO]: months selected as val set are <PeriodArray>
['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',
 '2016-02', '2016-03', '2016-04']
Length: 10, dtype: period[M]
2025-08-23 10:28:27 [INFO]: months selected as test set are <PeriodArray>
['2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11',
 '2016-12', '2017-01', '2017-02']
Length: 10, dtype: period[M]
2025-08-23 10:28:27 [INFO]: Total sample number: 730
2025-08-23 10:28:27 [INFO]: Training set size: 426 (58.36%)
2025-08-23 10:28:27 [INFO]: Validation set size: 152 (20.82%)
2025-08-23 10:28:27 [INFO]: Test set size: 152 (20.82%)
2025-08-23 10:28:27 [INFO]: Number of steps: 48
2025-08-23 10:28:27 [INFO]: Number of features: 132
2025-08-23 10:28:27 [INFO]: Train set missing rate: 11.67%
2025-08-23 10:28:27 [INFO]: Validating set missing rate: 10.80%
2025-08-23 10:28:27 [INFO]: Test set missing rate: 11.13%
✅ Dataset 'beijing_multisite_air_quality' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:28:27 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:28:27 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:28:28 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:28:28 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:28:28 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:28:28 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:28:29 [INFO]: Model placed on cuda:6
2025-08-23 10:28:29 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,938,756
 ├─ Trainable parameters: 1,198,212
 └─ Trainable ratio: 2.55%
2025-08-23 10:28:30 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): beijing_multisite_air_quality | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | beijing_multisite_air_quality | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:28:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:28:45 [INFO]: You're using dataset beijing_multisite_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/beijing_multisite_air_quality
2025-08-23 10:28:45 [INFO]: Dataset beijing_multisite_air_quality has already been downloaded. Processing directly...
2025-08-23 10:28:45 [INFO]: Dataset beijing_multisite_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:28:45 [INFO]: Loaded successfully!
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:28:45 [INFO]: There are total 12 stations, they are ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']
2025-08-23 10:28:45 [INFO]: Original df missing rate: 0.016
2025-08-23 10:28:45 [INFO]: months selected as train set are <PeriodArray>
['2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09',
 '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04',
 '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11',
 '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06']
Length: 28, dtype: period[M]
2025-08-23 10:28:45 [INFO]: months selected as val set are <PeriodArray>
['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',
 '2016-02', '2016-03', '2016-04']
Length: 10, dtype: period[M]
2025-08-23 10:28:45 [INFO]: months selected as test set are <PeriodArray>
['2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11',
 '2016-12', '2017-01', '2017-02']
Length: 10, dtype: period[M]
2025-08-23 10:28:46 [INFO]: Total sample number: 730
2025-08-23 10:28:46 [INFO]: Training set size: 426 (58.36%)
2025-08-23 10:28:46 [INFO]: Validation set size: 152 (20.82%)
2025-08-23 10:28:46 [INFO]: Test set size: 152 (20.82%)
2025-08-23 10:28:46 [INFO]: Number of steps: 48
2025-08-23 10:28:46 [INFO]: Number of features: 132
2025-08-23 10:28:46 [INFO]: Train set missing rate: 21.51%
2025-08-23 10:28:46 [INFO]: Validating set missing rate: 20.70%
2025-08-23 10:28:46 [INFO]: Test set missing rate: 20.98%
✅ Dataset 'beijing_multisite_air_quality' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:28:46 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:28:46 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:28:46 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:28:46 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:28:46 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:28:46 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:28:47 [INFO]: Model placed on cuda:6
2025-08-23 10:28:47 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,938,756
 ├─ Trainable parameters: 1,198,212
 └─ Trainable ratio: 2.55%
2025-08-23 10:28:48 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): beijing_multisite_air_quality | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | beijing_multisite_air_quality | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:29:07 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:29:07 [INFO]: You're using dataset beijing_multisite_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/beijing_multisite_air_quality
2025-08-23 10:29:07 [INFO]: Dataset beijing_multisite_air_quality has already been downloaded. Processing directly...
2025-08-23 10:29:07 [INFO]: Dataset beijing_multisite_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:29:07 [INFO]: Loaded successfully!
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:07 [INFO]: There are total 12 stations, they are ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']
2025-08-23 10:29:07 [INFO]: Original df missing rate: 0.016
2025-08-23 10:29:07 [INFO]: months selected as train set are <PeriodArray>
['2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09',
 '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04',
 '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11',
 '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06']
Length: 28, dtype: period[M]
2025-08-23 10:29:07 [INFO]: months selected as val set are <PeriodArray>
['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',
 '2016-02', '2016-03', '2016-04']
Length: 10, dtype: period[M]
2025-08-23 10:29:07 [INFO]: months selected as test set are <PeriodArray>
['2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11',
 '2016-12', '2017-01', '2017-02']
Length: 10, dtype: period[M]
2025-08-23 10:29:08 [INFO]: Total sample number: 730
2025-08-23 10:29:08 [INFO]: Training set size: 426 (58.36%)
2025-08-23 10:29:08 [INFO]: Validation set size: 152 (20.82%)
2025-08-23 10:29:08 [INFO]: Test set size: 152 (20.82%)
2025-08-23 10:29:08 [INFO]: Number of steps: 48
2025-08-23 10:29:08 [INFO]: Number of features: 132
2025-08-23 10:29:08 [INFO]: Train set missing rate: 31.34%
2025-08-23 10:29:08 [INFO]: Validating set missing rate: 30.61%
2025-08-23 10:29:08 [INFO]: Test set missing rate: 30.86%
✅ Dataset 'beijing_multisite_air_quality' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:29:08 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:29:08 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:29:08 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:29:08 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:29:08 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:29:08 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:29:10 [INFO]: Model placed on cuda:6
2025-08-23 10:29:10 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,938,756
 ├─ Trainable parameters: 1,198,212
 └─ Trainable ratio: 2.55%
2025-08-23 10:29:10 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): beijing_multisite_air_quality | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | beijing_multisite_air_quality | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:29:33 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:29:33 [INFO]: You're using dataset beijing_multisite_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/beijing_multisite_air_quality
2025-08-23 10:29:33 [INFO]: Dataset beijing_multisite_air_quality has already been downloaded. Processing directly...
2025-08-23 10:29:33 [INFO]: Dataset beijing_multisite_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:29:33 [INFO]: Loaded successfully!
2025-08-23 10:29:33 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:34 [INFO]: There are total 12 stations, they are ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']
2025-08-23 10:29:34 [INFO]: Original df missing rate: 0.016
2025-08-23 10:29:34 [INFO]: months selected as train set are <PeriodArray>
['2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09',
 '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04',
 '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11',
 '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06']
Length: 28, dtype: period[M]
2025-08-23 10:29:34 [INFO]: months selected as val set are <PeriodArray>
['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',
 '2016-02', '2016-03', '2016-04']
Length: 10, dtype: period[M]
2025-08-23 10:29:34 [INFO]: months selected as test set are <PeriodArray>
['2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11',
 '2016-12', '2017-01', '2017-02']
Length: 10, dtype: period[M]
2025-08-23 10:29:34 [INFO]: Total sample number: 730
2025-08-23 10:29:34 [INFO]: Training set size: 426 (58.36%)
2025-08-23 10:29:34 [INFO]: Validation set size: 152 (20.82%)
2025-08-23 10:29:34 [INFO]: Test set size: 152 (20.82%)
2025-08-23 10:29:34 [INFO]: Number of steps: 48
2025-08-23 10:29:34 [INFO]: Number of features: 132
2025-08-23 10:29:34 [INFO]: Train set missing rate: 41.13%
2025-08-23 10:29:34 [INFO]: Validating set missing rate: 40.51%
2025-08-23 10:29:34 [INFO]: Test set missing rate: 40.77%
✅ Dataset 'beijing_multisite_air_quality' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:29:34 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:29:34 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:29:35 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:29:35 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:29:35 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:29:35 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:29:36 [INFO]: Model placed on cuda:6
2025-08-23 10:29:36 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,938,756
 ├─ Trainable parameters: 1,198,212
 └─ Trainable ratio: 2.55%
2025-08-23 10:29:37 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): beijing_multisite_air_quality | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | beijing_multisite_air_quality | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:29:54 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:29:54 [INFO]: You're using dataset beijing_multisite_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/beijing_multisite_air_quality
2025-08-23 10:29:54 [INFO]: Dataset beijing_multisite_air_quality has already been downloaded. Processing directly...
2025-08-23 10:29:54 [INFO]: Dataset beijing_multisite_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:29:54 [INFO]: Loaded successfully!
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:54 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:55 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:55 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:55 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:55 [INFO]: Current dataframe shape: (35064, 18)
/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/benchpots/datasets/beijing_multisite_air_quality.py:60: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  current_df["date_time"] = pd.to_datetime(
2025-08-23 10:29:55 [INFO]: There are total 12 stations, they are ['Aotizhongxin', 'Changping', 'Dingling', 'Dongsi', 'Guanyuan', 'Gucheng', 'Huairou', 'Nongzhanguan', 'Shunyi', 'Tiantan', 'Wanliu', 'Wanshouxigong']
2025-08-23 10:29:55 [INFO]: Original df missing rate: 0.016
2025-08-23 10:29:55 [INFO]: months selected as train set are <PeriodArray>
['2013-03', '2013-04', '2013-05', '2013-06', '2013-07', '2013-08', '2013-09',
 '2013-10', '2013-11', '2013-12', '2014-01', '2014-02', '2014-03', '2014-04',
 '2014-05', '2014-06', '2014-07', '2014-08', '2014-09', '2014-10', '2014-11',
 '2014-12', '2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06']
Length: 28, dtype: period[M]
2025-08-23 10:29:55 [INFO]: months selected as val set are <PeriodArray>
['2015-07', '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01',
 '2016-02', '2016-03', '2016-04']
Length: 10, dtype: period[M]
2025-08-23 10:29:55 [INFO]: months selected as test set are <PeriodArray>
['2016-05', '2016-06', '2016-07', '2016-08', '2016-09', '2016-10', '2016-11',
 '2016-12', '2017-01', '2017-02']
Length: 10, dtype: period[M]
2025-08-23 10:29:55 [INFO]: Total sample number: 730
2025-08-23 10:29:55 [INFO]: Training set size: 426 (58.36%)
2025-08-23 10:29:55 [INFO]: Validation set size: 152 (20.82%)
2025-08-23 10:29:55 [INFO]: Test set size: 152 (20.82%)
2025-08-23 10:29:55 [INFO]: Number of steps: 48
2025-08-23 10:29:55 [INFO]: Number of features: 132
2025-08-23 10:29:55 [INFO]: Train set missing rate: 50.93%
2025-08-23 10:29:55 [INFO]: Validating set missing rate: 50.44%
2025-08-23 10:29:55 [INFO]: Test set missing rate: 50.71%
✅ Dataset 'beijing_multisite_air_quality' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:29:55 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:29:55 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:29:55 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:29:55 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/beijing_multisite_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:29:55 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:29:55 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:29:57 [INFO]: Model placed on cuda:6
2025-08-23 10:29:57 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,938,756
 ├─ Trainable parameters: 1,198,212
 └─ Trainable ratio: 2.55%
2025-08-23 10:29:58 [ERROR]: ❌ Exception: `predictions` mustn't contain NaN values, but detected NaN in it
Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 748, in _train_model
    results = self.model(inputs, calc_criterion=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/core.py", line 78, in forward
    loss = self.training_loss(reconstruction, X_ori, indicating_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/anaconda3/envs/pypots/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/modules/loss.py", line 81, in forward
    value = calc_mae(logits, targets, masks)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 98, in calc_mae
    lib = _check_inputs(predictions, targets, masks)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/nn/functional/error.py", line 34, in _check_inputs
    assert not lib.isnan(predictions).any(), "`predictions` mustn't contain NaN values, but detected NaN in it"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: `predictions` mustn't contain NaN values, but detected NaN in it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 80, in <module>
    main(args)
  File "/home/23r8105_messou/lab/iPyPOTS/main.py", line 59, in main
    mae, mse, rmse, mre = MODEL_PIPELINES[model_name](dataset, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/23r8105_messou/lab/iPyPOTS/pipeline/imputations/gpt4ts.py", line 58, in train_and_evaluate_gpt4ts
    gpt4ts.fit(train_set=train_set, val_set=val_set)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/imputation/gpt4ts/model.py", line 259, in fit
    self._train_model(train_dataloader, val_dataloader)
  File "/home/23r8105_messou/lab/iPyPOTS/pypots/base.py", line 825, in _train_model
    raise RuntimeError(
RuntimeError: Training got interrupted. Model was not trained. Please investigate the error printed above.
srun: error: ai-gpgpu14: task 0: Exited with exit code 1
❌ FAIL(1): beijing_multisite_air_quality | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | italy_air_quality | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:30:17 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:30:17 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-23 10:30:17 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-23 10:30:17 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:30:17 [INFO]: Loaded successfully!
2025-08-23 10:30:17 [INFO]: Total sample number: 192
2025-08-23 10:30:17 [INFO]: Training set size: 116 (60.42%)
2025-08-23 10:30:17 [INFO]: Validation set size: 38 (19.79%)
2025-08-23 10:30:17 [INFO]: Test set size: 38 (19.79%)
2025-08-23 10:30:17 [INFO]: Number of steps: 48
2025-08-23 10:30:17 [INFO]: Number of features: 13
2025-08-23 10:30:17 [INFO]: Train set missing rate: 9.87%
2025-08-23 10:30:17 [INFO]: Validating set missing rate: 9.86%
2025-08-23 10:30:17 [INFO]: Test set missing rate: 9.87%
✅ Dataset 'italy_air_quality' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:30:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:30:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:30:17 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:30:17 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:30:17 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:30:17 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:30:19 [INFO]: Model placed on cuda:6
2025-08-23 10:30:19 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,573,069
 ├─ Trainable parameters: 832,525
 └─ Trainable ratio: 1.79%
2025-08-23 10:30:20 [INFO]: Epoch 001 - training loss (MAE): 0.4383, validation MSE: 0.5185
2025-08-23 10:30:20 [INFO]: Epoch 002 - training loss (MAE): 0.3307, validation MSE: 0.4206
2025-08-23 10:30:20 [INFO]: Epoch 003 - training loss (MAE): 0.2884, validation MSE: 0.4534
2025-08-23 10:30:20 [INFO]: Epoch 004 - training loss (MAE): 0.2698, validation MSE: 0.4189
2025-08-23 10:30:20 [INFO]: Epoch 005 - training loss (MAE): 0.2555, validation MSE: 0.3407
2025-08-23 10:30:21 [INFO]: Epoch 006 - training loss (MAE): 0.2322, validation MSE: 0.2947
2025-08-23 10:30:21 [INFO]: Epoch 007 - training loss (MAE): 0.2258, validation MSE: 0.2703
2025-08-23 10:30:21 [INFO]: Epoch 008 - training loss (MAE): 0.2287, validation MSE: 0.2523
2025-08-23 10:30:21 [INFO]: Epoch 009 - training loss (MAE): 0.2208, validation MSE: 0.2565
2025-08-23 10:30:21 [INFO]: Epoch 010 - training loss (MAE): 0.2112, validation MSE: 0.2653
2025-08-23 10:30:21 [INFO]: Epoch 011 - training loss (MAE): 0.2066, validation MSE: 0.2490
2025-08-23 10:30:21 [INFO]: Epoch 012 - training loss (MAE): 0.2021, validation MSE: 0.2468
2025-08-23 10:30:21 [INFO]: Epoch 013 - training loss (MAE): 0.2033, validation MSE: 0.2347
2025-08-23 10:30:22 [INFO]: Epoch 014 - training loss (MAE): 0.1967, validation MSE: 0.2236
2025-08-23 10:30:22 [INFO]: Epoch 015 - training loss (MAE): 0.1908, validation MSE: 0.2349
2025-08-23 10:30:22 [INFO]: Finished training. The best model is from epoch#14.
2025-08-23 10:30:22 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1787| MSE: 0.1207| RMSE: 0.3474| MRE: 0.2326| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: italy_air_quality | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | italy_air_quality | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:30:45 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:30:45 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-23 10:30:45 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-23 10:30:45 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:30:45 [INFO]: Loaded successfully!
2025-08-23 10:30:45 [INFO]: Total sample number: 192
2025-08-23 10:30:45 [INFO]: Training set size: 116 (60.42%)
2025-08-23 10:30:45 [INFO]: Validation set size: 38 (19.79%)
2025-08-23 10:30:45 [INFO]: Test set size: 38 (19.79%)
2025-08-23 10:30:45 [INFO]: Number of steps: 48
2025-08-23 10:30:45 [INFO]: Number of features: 13
2025-08-23 10:30:45 [INFO]: Train set missing rate: 19.79%
2025-08-23 10:30:45 [INFO]: Validating set missing rate: 19.86%
2025-08-23 10:30:45 [INFO]: Test set missing rate: 19.88%
✅ Dataset 'italy_air_quality' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:30:45 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:30:45 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:30:46 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:30:46 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:30:46 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:30:46 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:30:48 [INFO]: Model placed on cuda:6
2025-08-23 10:30:48 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,573,069
 ├─ Trainable parameters: 832,525
 └─ Trainable ratio: 1.79%
2025-08-23 10:30:49 [INFO]: Epoch 001 - training loss (MAE): 0.4381, validation MSE: 0.5741
2025-08-23 10:30:49 [INFO]: Epoch 002 - training loss (MAE): 0.3406, validation MSE: 0.4361
2025-08-23 10:30:49 [INFO]: Epoch 003 - training loss (MAE): 0.2916, validation MSE: 0.4602
2025-08-23 10:30:49 [INFO]: Epoch 004 - training loss (MAE): 0.2747, validation MSE: 0.4392
2025-08-23 10:30:49 [INFO]: Epoch 005 - training loss (MAE): 0.2649, validation MSE: 0.3693
2025-08-23 10:30:49 [INFO]: Epoch 006 - training loss (MAE): 0.2387, validation MSE: 0.3214
2025-08-23 10:30:49 [INFO]: Epoch 007 - training loss (MAE): 0.2348, validation MSE: 0.2939
2025-08-23 10:30:49 [INFO]: Epoch 008 - training loss (MAE): 0.2355, validation MSE: 0.2738
2025-08-23 10:30:50 [INFO]: Epoch 009 - training loss (MAE): 0.2300, validation MSE: 0.2666
2025-08-23 10:30:50 [INFO]: Epoch 010 - training loss (MAE): 0.2215, validation MSE: 0.2726
2025-08-23 10:30:50 [INFO]: Epoch 011 - training loss (MAE): 0.2141, validation MSE: 0.2623
2025-08-23 10:30:50 [INFO]: Epoch 012 - training loss (MAE): 0.2095, validation MSE: 0.2578
2025-08-23 10:30:50 [INFO]: Epoch 013 - training loss (MAE): 0.2135, validation MSE: 0.2508
2025-08-23 10:30:50 [INFO]: Epoch 014 - training loss (MAE): 0.2103, validation MSE: 0.2479
2025-08-23 10:30:50 [INFO]: Epoch 015 - training loss (MAE): 0.2031, validation MSE: 0.2443
2025-08-23 10:30:50 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:30:51 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1879| MSE: 0.1350| RMSE: 0.3674| MRE: 0.2425| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: italy_air_quality | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | italy_air_quality | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:31:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:31:10 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-23 10:31:10 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-23 10:31:10 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:31:10 [INFO]: Loaded successfully!
✅ Dataset 'italy_air_quality' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:31:10 [INFO]: Total sample number: 192
2025-08-23 10:31:10 [INFO]: Training set size: 116 (60.42%)
2025-08-23 10:31:10 [INFO]: Validation set size: 38 (19.79%)
2025-08-23 10:31:10 [INFO]: Test set size: 38 (19.79%)
2025-08-23 10:31:10 [INFO]: Number of steps: 48
2025-08-23 10:31:10 [INFO]: Number of features: 13
2025-08-23 10:31:10 [INFO]: Train set missing rate: 29.80%
2025-08-23 10:31:10 [INFO]: Validating set missing rate: 29.90%
2025-08-23 10:31:10 [INFO]: Test set missing rate: 30.05%
2025-08-23 10:31:10 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:31:10 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:31:11 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:31:11 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:31:11 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:31:11 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:31:12 [INFO]: Model placed on cuda:6
2025-08-23 10:31:12 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,573,069
 ├─ Trainable parameters: 832,525
 └─ Trainable ratio: 1.79%
2025-08-23 10:31:13 [INFO]: Epoch 001 - training loss (MAE): 0.4423, validation MSE: 0.5920
2025-08-23 10:31:13 [INFO]: Epoch 002 - training loss (MAE): 0.3519, validation MSE: 0.4517
2025-08-23 10:31:13 [INFO]: Epoch 003 - training loss (MAE): 0.3025, validation MSE: 0.4385
2025-08-23 10:31:13 [INFO]: Epoch 004 - training loss (MAE): 0.2818, validation MSE: 0.4471
2025-08-23 10:31:13 [INFO]: Epoch 005 - training loss (MAE): 0.2713, validation MSE: 0.3936
2025-08-23 10:31:13 [INFO]: Epoch 006 - training loss (MAE): 0.2468, validation MSE: 0.3512
2025-08-23 10:31:13 [INFO]: Epoch 007 - training loss (MAE): 0.2443, validation MSE: 0.3271
2025-08-23 10:31:14 [INFO]: Epoch 008 - training loss (MAE): 0.2454, validation MSE: 0.3093
2025-08-23 10:31:14 [INFO]: Epoch 009 - training loss (MAE): 0.2377, validation MSE: 0.2987
2025-08-23 10:31:14 [INFO]: Epoch 010 - training loss (MAE): 0.2310, validation MSE: 0.3009
2025-08-23 10:31:14 [INFO]: Epoch 011 - training loss (MAE): 0.2259, validation MSE: 0.2947
2025-08-23 10:31:14 [INFO]: Epoch 012 - training loss (MAE): 0.2219, validation MSE: 0.2965
2025-08-23 10:31:14 [INFO]: Epoch 013 - training loss (MAE): 0.2265, validation MSE: 0.2856
2025-08-23 10:31:14 [INFO]: Epoch 014 - training loss (MAE): 0.2203, validation MSE: 0.2886
2025-08-23 10:31:15 [INFO]: Epoch 015 - training loss (MAE): 0.2157, validation MSE: 0.2861
2025-08-23 10:31:15 [INFO]: Finished training. The best model is from epoch#13.
2025-08-23 10:31:15 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.2083| MSE: 0.1691| RMSE: 0.4112| MRE: 0.2665| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: italy_air_quality | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | italy_air_quality | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:31:33 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:31:33 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-23 10:31:33 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-23 10:31:33 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:31:33 [INFO]: Loaded successfully!
2025-08-23 10:31:33 [INFO]: Total sample number: 192
2025-08-23 10:31:33 [INFO]: Training set size: 116 (60.42%)
2025-08-23 10:31:33 [INFO]: Validation set size: 38 (19.79%)
2025-08-23 10:31:33 [INFO]: Test set size: 38 (19.79%)
2025-08-23 10:31:33 [INFO]: Number of steps: 48
2025-08-23 10:31:33 [INFO]: Number of features: 13
2025-08-23 10:31:33 [INFO]: Train set missing rate: 39.84%
2025-08-23 10:31:33 [INFO]: Validating set missing rate: 39.87%
2025-08-23 10:31:33 [INFO]: Test set missing rate: 40.52%
✅ Dataset 'italy_air_quality' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:31:33 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:31:33 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:31:33 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:31:33 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:31:33 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:31:33 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:31:34 [INFO]: Model placed on cuda:6
2025-08-23 10:31:34 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,573,069
 ├─ Trainable parameters: 832,525
 └─ Trainable ratio: 1.79%
2025-08-23 10:31:35 [INFO]: Epoch 001 - training loss (MAE): 0.4483, validation MSE: 0.6469
2025-08-23 10:31:35 [INFO]: Epoch 002 - training loss (MAE): 0.3682, validation MSE: 0.4586
2025-08-23 10:31:35 [INFO]: Epoch 003 - training loss (MAE): 0.3166, validation MSE: 0.4174
2025-08-23 10:31:35 [INFO]: Epoch 004 - training loss (MAE): 0.2905, validation MSE: 0.4157
2025-08-23 10:31:35 [INFO]: Epoch 005 - training loss (MAE): 0.2831, validation MSE: 0.3995
2025-08-23 10:31:35 [INFO]: Epoch 006 - training loss (MAE): 0.2638, validation MSE: 0.3642
2025-08-23 10:31:35 [INFO]: Epoch 007 - training loss (MAE): 0.2592, validation MSE: 0.3381
2025-08-23 10:31:36 [INFO]: Epoch 008 - training loss (MAE): 0.2632, validation MSE: 0.3154
2025-08-23 10:31:36 [INFO]: Epoch 009 - training loss (MAE): 0.2529, validation MSE: 0.2942
2025-08-23 10:31:36 [INFO]: Epoch 010 - training loss (MAE): 0.2451, validation MSE: 0.2938
2025-08-23 10:31:36 [INFO]: Epoch 011 - training loss (MAE): 0.2411, validation MSE: 0.2842
2025-08-23 10:31:36 [INFO]: Epoch 012 - training loss (MAE): 0.2375, validation MSE: 0.2944
2025-08-23 10:31:36 [INFO]: Epoch 013 - training loss (MAE): 0.2424, validation MSE: 0.2907
2025-08-23 10:31:37 [INFO]: Epoch 014 - training loss (MAE): 0.2379, validation MSE: 0.2847
2025-08-23 10:31:37 [INFO]: Epoch 015 - training loss (MAE): 0.2290, validation MSE: 0.2779
2025-08-23 10:31:37 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:31:37 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.2159| MSE: 0.1816| RMSE: 0.4261| MRE: 0.2771| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: italy_air_quality | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | italy_air_quality | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=48, N_FEATURES=36)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:31:49 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:31:49 [INFO]: You're using dataset italy_air_quality, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/italy_air_quality
2025-08-23 10:31:49 [INFO]: Dataset italy_air_quality has already been downloaded. Processing directly...
2025-08-23 10:31:49 [INFO]: Dataset italy_air_quality has already been cached. Loading from cache directly...
2025-08-23 10:31:49 [INFO]: Loaded successfully!
✅ Dataset 'italy_air_quality' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:31:49 [INFO]: Total sample number: 192
2025-08-23 10:31:49 [INFO]: Training set size: 116 (60.42%)
2025-08-23 10:31:49 [INFO]: Validation set size: 38 (19.79%)
2025-08-23 10:31:49 [INFO]: Test set size: 38 (19.79%)
2025-08-23 10:31:49 [INFO]: Number of steps: 48
2025-08-23 10:31:49 [INFO]: Number of features: 13
2025-08-23 10:31:49 [INFO]: Train set missing rate: 50.11%
2025-08-23 10:31:49 [INFO]: Validating set missing rate: 50.03%
2025-08-23 10:31:49 [INFO]: Test set missing rate: 50.12%
2025-08-23 10:31:49 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:31:49 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:31:50 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:31:50 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:31:50 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:31:50 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:31:51 [INFO]: Model placed on cuda:6
2025-08-23 10:31:51 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,573,069
 ├─ Trainable parameters: 832,525
 └─ Trainable ratio: 1.79%
2025-08-23 10:31:51 [INFO]: Epoch 001 - training loss (MAE): 0.4479, validation MSE: 0.6835
2025-08-23 10:31:51 [INFO]: Epoch 002 - training loss (MAE): 0.3841, validation MSE: 0.5178
2025-08-23 10:31:51 [INFO]: Epoch 003 - training loss (MAE): 0.3352, validation MSE: 0.4325
2025-08-23 10:31:51 [INFO]: Epoch 004 - training loss (MAE): 0.3066, validation MSE: 0.4050
2025-08-23 10:31:51 [INFO]: Epoch 005 - training loss (MAE): 0.2955, validation MSE: 0.4137
2025-08-23 10:31:51 [INFO]: Epoch 006 - training loss (MAE): 0.2817, validation MSE: 0.4022
2025-08-23 10:31:51 [INFO]: Epoch 007 - training loss (MAE): 0.2740, validation MSE: 0.3917
2025-08-23 10:31:51 [INFO]: Epoch 008 - training loss (MAE): 0.2843, validation MSE: 0.3473
2025-08-23 10:31:52 [INFO]: Epoch 009 - training loss (MAE): 0.2690, validation MSE: 0.3242
2025-08-23 10:31:52 [INFO]: Epoch 010 - training loss (MAE): 0.2587, validation MSE: 0.3116
2025-08-23 10:31:52 [INFO]: Epoch 011 - training loss (MAE): 0.2596, validation MSE: 0.3235
2025-08-23 10:31:52 [INFO]: Epoch 012 - training loss (MAE): 0.2497, validation MSE: 0.3064
2025-08-23 10:31:52 [INFO]: Epoch 013 - training loss (MAE): 0.2540, validation MSE: 0.3120
2025-08-23 10:31:52 [INFO]: Epoch 014 - training loss (MAE): 0.2484, validation MSE: 0.3048
2025-08-23 10:31:52 [INFO]: Epoch 015 - training loss (MAE): 0.2497, validation MSE: 0.3120
2025-08-23 10:31:52 [INFO]: Finished training. The best model is from epoch#14.
2025-08-23 10:31:52 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.2285| MSE: 0.1977| RMSE: 0.4446| MRE: 0.2943| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/italy_air_quality/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: italy_air_quality | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | pems_traffic | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=228)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:32:01 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:32:01 [INFO]: You're using dataset pems_traffic, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/pems_traffic
2025-08-23 10:32:01 [INFO]: Dataset pems_traffic has already been downloaded. Processing directly...
2025-08-23 10:32:01 [INFO]: Dataset pems_traffic has already been cached. Loading from cache directly...
2025-08-23 10:32:02 [INFO]: Loaded successfully!
2025-08-23 10:32:02 [INFO]: months selected as train set are <PeriodArray>
['2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',
 '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02',
 '2016-03']
Length: 15, dtype: period[M]
2025-08-23 10:32:02 [INFO]: months selected as val set are <PeriodArray>
['2016-04', '2016-05', '2016-06', '2016-07']
Length: 4, dtype: period[M]
2025-08-23 10:32:02 [INFO]: months selected as test set are <PeriodArray>
['2016-08', '2016-09', '2016-10', '2016-11', '2016-12']
Length: 5, dtype: period[M]
2025-08-23 10:32:02 [INFO]: Total sample number: 182
2025-08-23 10:32:02 [INFO]: Training set size: 114 (62.64%)
2025-08-23 10:32:02 [INFO]: Validation set size: 30 (16.48%)
2025-08-23 10:32:02 [INFO]: Test set size: 38 (20.88%)
2025-08-23 10:32:02 [INFO]: Number of steps: 96
2025-08-23 10:32:02 [INFO]: Number of features: 862
2025-08-23 10:32:02 [INFO]: Train set missing rate: 9.98%
2025-08-23 10:32:02 [INFO]: Validating set missing rate: 10.03%
2025-08-23 10:32:02 [INFO]: Test set missing rate: 10.00%
✅ Dataset 'pems_traffic' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:32:02 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:32:02 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:32:02 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:32:02 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:32:02 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:32:02 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:32:04 [INFO]: Model placed on cuda:6
2025-08-23 10:32:04 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 49,182,046
 ├─ Trainable parameters: 3,441,502
 └─ Trainable ratio: 7.00%
2025-08-23 10:32:11 [INFO]: Epoch 001 - training loss (MAE): 0.7160, validation MSE: 0.7763
2025-08-23 10:32:16 [INFO]: Epoch 002 - training loss (MAE): 0.4794, validation MSE: 0.6269
2025-08-23 10:32:26 [INFO]: Epoch 003 - training loss (MAE): 0.4130, validation MSE: 0.5472
2025-08-23 10:32:41 [INFO]: Epoch 004 - training loss (MAE): 0.3719, validation MSE: 0.4931
2025-08-23 10:32:53 [INFO]: Epoch 005 - training loss (MAE): 0.3432, validation MSE: 0.4605
2025-08-23 10:33:03 [INFO]: Epoch 006 - training loss (MAE): 0.3243, validation MSE: 0.4319
2025-08-23 10:33:11 [INFO]: Epoch 007 - training loss (MAE): 0.3119, validation MSE: 0.4167
2025-08-23 10:33:27 [INFO]: Epoch 008 - training loss (MAE): 0.3012, validation MSE: 0.4096
2025-08-23 10:33:38 [INFO]: Epoch 009 - training loss (MAE): 0.2920, validation MSE: 0.4003
2025-08-23 10:33:51 [INFO]: Epoch 010 - training loss (MAE): 0.2855, validation MSE: 0.3878
2025-08-23 10:34:02 [INFO]: Epoch 011 - training loss (MAE): 0.2794, validation MSE: 0.3857
2025-08-23 10:34:12 [INFO]: Epoch 012 - training loss (MAE): 0.2716, validation MSE: 0.3794
2025-08-23 10:34:19 [INFO]: Epoch 013 - training loss (MAE): 0.2660, validation MSE: 0.3744
2025-08-23 10:34:28 [INFO]: Epoch 014 - training loss (MAE): 0.2648, validation MSE: 0.3765
2025-08-23 10:34:38 [INFO]: Epoch 015 - training loss (MAE): 0.2613, validation MSE: 0.3801
2025-08-23 10:34:38 [INFO]: Finished training. The best model is from epoch#13.
2025-08-23 10:34:39 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.3070| MSE: 0.5722| RMSE: 0.7564| MRE: 0.3807| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: pems_traffic | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | pems_traffic | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=228)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:35:16 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:35:16 [INFO]: You're using dataset pems_traffic, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/pems_traffic
2025-08-23 10:35:16 [INFO]: Dataset pems_traffic has already been downloaded. Processing directly...
2025-08-23 10:35:16 [INFO]: Dataset pems_traffic has already been cached. Loading from cache directly...
2025-08-23 10:35:16 [INFO]: Loaded successfully!
2025-08-23 10:35:16 [INFO]: months selected as train set are <PeriodArray>
['2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',
 '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02',
 '2016-03']
Length: 15, dtype: period[M]
2025-08-23 10:35:16 [INFO]: months selected as val set are <PeriodArray>
['2016-04', '2016-05', '2016-06', '2016-07']
Length: 4, dtype: period[M]
2025-08-23 10:35:16 [INFO]: months selected as test set are <PeriodArray>
['2016-08', '2016-09', '2016-10', '2016-11', '2016-12']
Length: 5, dtype: period[M]
2025-08-23 10:35:17 [INFO]: Total sample number: 182
2025-08-23 10:35:17 [INFO]: Training set size: 114 (62.64%)
2025-08-23 10:35:17 [INFO]: Validation set size: 30 (16.48%)
2025-08-23 10:35:17 [INFO]: Test set size: 38 (20.88%)
2025-08-23 10:35:17 [INFO]: Number of steps: 96
2025-08-23 10:35:17 [INFO]: Number of features: 862
2025-08-23 10:35:17 [INFO]: Train set missing rate: 20.00%
2025-08-23 10:35:17 [INFO]: Validating set missing rate: 20.00%
2025-08-23 10:35:17 [INFO]: Test set missing rate: 20.01%
✅ Dataset 'pems_traffic' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:35:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:35:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:35:18 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:35:18 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:35:18 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:35:18 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:35:20 [INFO]: Model placed on cuda:6
2025-08-23 10:35:20 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 49,182,046
 ├─ Trainable parameters: 3,441,502
 └─ Trainable ratio: 7.00%
2025-08-23 10:35:36 [INFO]: Epoch 001 - training loss (MAE): 0.7172, validation MSE: 0.7786
2025-08-23 10:35:51 [INFO]: Epoch 002 - training loss (MAE): 0.4822, validation MSE: 0.6269
2025-08-23 10:36:04 [INFO]: Epoch 003 - training loss (MAE): 0.4165, validation MSE: 0.5464
2025-08-23 10:36:18 [INFO]: Epoch 004 - training loss (MAE): 0.3754, validation MSE: 0.4902
2025-08-23 10:36:31 [INFO]: Epoch 005 - training loss (MAE): 0.3465, validation MSE: 0.4565
2025-08-23 10:36:43 [INFO]: Epoch 006 - training loss (MAE): 0.3276, validation MSE: 0.4285
2025-08-23 10:36:58 [INFO]: Epoch 007 - training loss (MAE): 0.3152, validation MSE: 0.4136
2025-08-23 10:37:09 [INFO]: Epoch 008 - training loss (MAE): 0.3044, validation MSE: 0.4057
2025-08-23 10:37:18 [INFO]: Epoch 009 - training loss (MAE): 0.2957, validation MSE: 0.3986
2025-08-23 10:37:33 [INFO]: Epoch 010 - training loss (MAE): 0.2890, validation MSE: 0.3884
2025-08-23 10:37:50 [INFO]: Epoch 011 - training loss (MAE): 0.2829, validation MSE: 0.3844
2025-08-23 10:38:04 [INFO]: Epoch 012 - training loss (MAE): 0.2753, validation MSE: 0.3786
2025-08-23 10:38:14 [INFO]: Epoch 013 - training loss (MAE): 0.2700, validation MSE: 0.3742
2025-08-23 10:38:21 [INFO]: Epoch 014 - training loss (MAE): 0.2686, validation MSE: 0.3758
2025-08-23 10:38:33 [INFO]: Epoch 015 - training loss (MAE): 0.2654, validation MSE: 0.3800
2025-08-23 10:38:33 [INFO]: Finished training. The best model is from epoch#13.
2025-08-23 10:38:33 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.3101| MSE: 0.5733| RMSE: 0.7572| MRE: 0.3851| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: pems_traffic | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | pems_traffic | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=228)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:38:58 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:38:58 [INFO]: You're using dataset pems_traffic, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/pems_traffic
2025-08-23 10:38:58 [INFO]: Dataset pems_traffic has already been downloaded. Processing directly...
2025-08-23 10:38:58 [INFO]: Dataset pems_traffic has already been cached. Loading from cache directly...
2025-08-23 10:38:58 [INFO]: Loaded successfully!
2025-08-23 10:38:58 [INFO]: months selected as train set are <PeriodArray>
['2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',
 '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02',
 '2016-03']
Length: 15, dtype: period[M]
2025-08-23 10:38:58 [INFO]: months selected as val set are <PeriodArray>
['2016-04', '2016-05', '2016-06', '2016-07']
Length: 4, dtype: period[M]
2025-08-23 10:38:58 [INFO]: months selected as test set are <PeriodArray>
['2016-08', '2016-09', '2016-10', '2016-11', '2016-12']
Length: 5, dtype: period[M]
2025-08-23 10:38:59 [INFO]: Total sample number: 182
2025-08-23 10:38:59 [INFO]: Training set size: 114 (62.64%)
2025-08-23 10:38:59 [INFO]: Validation set size: 30 (16.48%)
2025-08-23 10:38:59 [INFO]: Test set size: 38 (20.88%)
2025-08-23 10:38:59 [INFO]: Number of steps: 96
2025-08-23 10:38:59 [INFO]: Number of features: 862
2025-08-23 10:39:00 [INFO]: Train set missing rate: 30.01%
2025-08-23 10:39:00 [INFO]: Validating set missing rate: 29.97%
2025-08-23 10:39:00 [INFO]: Test set missing rate: 30.02%
✅ Dataset 'pems_traffic' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:39:00 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:39:00 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:39:00 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:39:00 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:39:00 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:39:00 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:39:02 [INFO]: Model placed on cuda:6
2025-08-23 10:39:02 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 49,182,046
 ├─ Trainable parameters: 3,441,502
 └─ Trainable ratio: 7.00%
2025-08-23 10:39:18 [INFO]: Epoch 001 - training loss (MAE): 0.7182, validation MSE: 0.7837
2025-08-23 10:39:32 [INFO]: Epoch 002 - training loss (MAE): 0.4853, validation MSE: 0.6339
2025-08-23 10:39:47 [INFO]: Epoch 003 - training loss (MAE): 0.4208, validation MSE: 0.5523
2025-08-23 10:40:01 [INFO]: Epoch 004 - training loss (MAE): 0.3796, validation MSE: 0.4954
2025-08-23 10:40:15 [INFO]: Epoch 005 - training loss (MAE): 0.3504, validation MSE: 0.4627
2025-08-23 10:40:30 [INFO]: Epoch 006 - training loss (MAE): 0.3319, validation MSE: 0.4340
2025-08-23 10:40:45 [INFO]: Epoch 007 - training loss (MAE): 0.3198, validation MSE: 0.4186
2025-08-23 10:41:01 [INFO]: Epoch 008 - training loss (MAE): 0.3092, validation MSE: 0.4120
2025-08-23 10:41:12 [INFO]: Epoch 009 - training loss (MAE): 0.3006, validation MSE: 0.4037
2025-08-23 10:41:22 [INFO]: Epoch 010 - training loss (MAE): 0.2942, validation MSE: 0.3933
2025-08-23 10:41:37 [INFO]: Epoch 011 - training loss (MAE): 0.2879, validation MSE: 0.3887
2025-08-23 10:41:55 [INFO]: Epoch 012 - training loss (MAE): 0.2806, validation MSE: 0.3842
2025-08-23 10:42:16 [INFO]: Epoch 013 - training loss (MAE): 0.2755, validation MSE: 0.3800
2025-08-23 10:42:31 [INFO]: Epoch 014 - training loss (MAE): 0.2739, validation MSE: 0.3808
2025-08-23 10:42:48 [INFO]: Epoch 015 - training loss (MAE): 0.2708, validation MSE: 0.3847
2025-08-23 10:42:48 [INFO]: Finished training. The best model is from epoch#13.
2025-08-23 10:42:48 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.3147| MSE: 0.5791| RMSE: 0.7610| MRE: 0.3906| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: pems_traffic | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | pems_traffic | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=228)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:43:10 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:43:10 [INFO]: You're using dataset pems_traffic, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/pems_traffic
2025-08-23 10:43:10 [INFO]: Dataset pems_traffic has already been downloaded. Processing directly...
2025-08-23 10:43:10 [INFO]: Dataset pems_traffic has already been cached. Loading from cache directly...
2025-08-23 10:43:10 [INFO]: Loaded successfully!
2025-08-23 10:43:10 [INFO]: months selected as train set are <PeriodArray>
['2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',
 '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02',
 '2016-03']
Length: 15, dtype: period[M]
2025-08-23 10:43:10 [INFO]: months selected as val set are <PeriodArray>
['2016-04', '2016-05', '2016-06', '2016-07']
Length: 4, dtype: period[M]
2025-08-23 10:43:10 [INFO]: months selected as test set are <PeriodArray>
['2016-08', '2016-09', '2016-10', '2016-11', '2016-12']
Length: 5, dtype: period[M]
2025-08-23 10:43:11 [INFO]: Total sample number: 182
2025-08-23 10:43:11 [INFO]: Training set size: 114 (62.64%)
2025-08-23 10:43:11 [INFO]: Validation set size: 30 (16.48%)
2025-08-23 10:43:11 [INFO]: Test set size: 38 (20.88%)
2025-08-23 10:43:11 [INFO]: Number of steps: 96
2025-08-23 10:43:11 [INFO]: Number of features: 862
2025-08-23 10:43:11 [INFO]: Train set missing rate: 40.01%
2025-08-23 10:43:11 [INFO]: Validating set missing rate: 39.94%
2025-08-23 10:43:11 [INFO]: Test set missing rate: 40.04%
✅ Dataset 'pems_traffic' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:43:11 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:43:11 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:43:12 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:43:12 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:43:12 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:43:12 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:43:13 [INFO]: Model placed on cuda:6
2025-08-23 10:43:13 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 49,182,046
 ├─ Trainable parameters: 3,441,502
 └─ Trainable ratio: 7.00%
2025-08-23 10:43:24 [INFO]: Epoch 001 - training loss (MAE): 0.7202, validation MSE: 0.7864
2025-08-23 10:43:31 [INFO]: Epoch 002 - training loss (MAE): 0.4896, validation MSE: 0.6410
2025-08-23 10:43:39 [INFO]: Epoch 003 - training loss (MAE): 0.4267, validation MSE: 0.5593
2025-08-23 10:43:46 [INFO]: Epoch 004 - training loss (MAE): 0.3861, validation MSE: 0.5007
2025-08-23 10:43:55 [INFO]: Epoch 005 - training loss (MAE): 0.3565, validation MSE: 0.4690
2025-08-23 10:44:06 [INFO]: Epoch 006 - training loss (MAE): 0.3375, validation MSE: 0.4398
2025-08-23 10:44:16 [INFO]: Epoch 007 - training loss (MAE): 0.3265, validation MSE: 0.4220
2025-08-23 10:44:26 [INFO]: Epoch 008 - training loss (MAE): 0.3154, validation MSE: 0.4175
2025-08-23 10:44:41 [INFO]: Epoch 009 - training loss (MAE): 0.3067, validation MSE: 0.4103
2025-08-23 10:44:52 [INFO]: Epoch 010 - training loss (MAE): 0.3007, validation MSE: 0.3974
2025-08-23 10:45:02 [INFO]: Epoch 011 - training loss (MAE): 0.2940, validation MSE: 0.3916
2025-08-23 10:45:09 [INFO]: Epoch 012 - training loss (MAE): 0.2872, validation MSE: 0.3898
2025-08-23 10:45:17 [INFO]: Epoch 013 - training loss (MAE): 0.2822, validation MSE: 0.3862
2025-08-23 10:45:26 [INFO]: Epoch 014 - training loss (MAE): 0.2807, validation MSE: 0.3846
2025-08-23 10:45:40 [INFO]: Epoch 015 - training loss (MAE): 0.2772, validation MSE: 0.3844
2025-08-23 10:45:40 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:45:40 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.3215| MSE: 0.5950| RMSE: 0.7714| MRE: 0.3990| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: pems_traffic | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | pems_traffic | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=228)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:45:59 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:45:59 [INFO]: You're using dataset pems_traffic, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/pems_traffic
2025-08-23 10:45:59 [INFO]: Dataset pems_traffic has already been downloaded. Processing directly...
2025-08-23 10:45:59 [INFO]: Dataset pems_traffic has already been cached. Loading from cache directly...
2025-08-23 10:45:59 [INFO]: Loaded successfully!
2025-08-23 10:45:59 [INFO]: months selected as train set are <PeriodArray>
['2015-01', '2015-02', '2015-03', '2015-04', '2015-05', '2015-06', '2015-07',
 '2015-08', '2015-09', '2015-10', '2015-11', '2015-12', '2016-01', '2016-02',
 '2016-03']
Length: 15, dtype: period[M]
2025-08-23 10:45:59 [INFO]: months selected as val set are <PeriodArray>
['2016-04', '2016-05', '2016-06', '2016-07']
Length: 4, dtype: period[M]
2025-08-23 10:45:59 [INFO]: months selected as test set are <PeriodArray>
['2016-08', '2016-09', '2016-10', '2016-11', '2016-12']
Length: 5, dtype: period[M]
2025-08-23 10:46:00 [INFO]: Total sample number: 182
2025-08-23 10:46:00 [INFO]: Training set size: 114 (62.64%)
2025-08-23 10:46:00 [INFO]: Validation set size: 30 (16.48%)
2025-08-23 10:46:00 [INFO]: Test set size: 38 (20.88%)
2025-08-23 10:46:00 [INFO]: Number of steps: 96
2025-08-23 10:46:00 [INFO]: Number of features: 862
2025-08-23 10:46:00 [INFO]: Train set missing rate: 50.01%
2025-08-23 10:46:00 [INFO]: Validating set missing rate: 49.93%
2025-08-23 10:46:00 [INFO]: Test set missing rate: 50.04%
✅ Dataset 'pems_traffic' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:46:00 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:46:00 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:46:01 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:46:01 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:46:01 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:46:01 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:46:03 [INFO]: Model placed on cuda:6
2025-08-23 10:46:03 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 49,182,046
 ├─ Trainable parameters: 3,441,502
 └─ Trainable ratio: 7.00%
2025-08-23 10:46:22 [INFO]: Epoch 001 - training loss (MAE): 0.7223, validation MSE: 0.7950
2025-08-23 10:46:36 [INFO]: Epoch 002 - training loss (MAE): 0.4948, validation MSE: 0.6565
2025-08-23 10:46:52 [INFO]: Epoch 003 - training loss (MAE): 0.4338, validation MSE: 0.5695
2025-08-23 10:47:04 [INFO]: Epoch 004 - training loss (MAE): 0.3945, validation MSE: 0.5091
2025-08-23 10:47:20 [INFO]: Epoch 005 - training loss (MAE): 0.3648, validation MSE: 0.4775
2025-08-23 10:47:35 [INFO]: Epoch 006 - training loss (MAE): 0.3454, validation MSE: 0.4505
2025-08-23 10:47:50 [INFO]: Epoch 007 - training loss (MAE): 0.3346, validation MSE: 0.4304
2025-08-23 10:48:03 [INFO]: Epoch 008 - training loss (MAE): 0.3237, validation MSE: 0.4257
2025-08-23 10:48:17 [INFO]: Epoch 009 - training loss (MAE): 0.3152, validation MSE: 0.4202
2025-08-23 10:48:31 [INFO]: Epoch 010 - training loss (MAE): 0.3092, validation MSE: 0.4094
2025-08-23 10:48:46 [INFO]: Epoch 011 - training loss (MAE): 0.3028, validation MSE: 0.4006
2025-08-23 10:49:01 [INFO]: Epoch 012 - training loss (MAE): 0.2963, validation MSE: 0.3950
2025-08-23 10:49:15 [INFO]: Epoch 013 - training loss (MAE): 0.2910, validation MSE: 0.3929
2025-08-23 10:49:31 [INFO]: Epoch 014 - training loss (MAE): 0.2897, validation MSE: 0.3938
2025-08-23 10:49:44 [INFO]: Epoch 015 - training loss (MAE): 0.2864, validation MSE: 0.3919
2025-08-23 10:49:44 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:49:44 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.3290| MSE: 0.5972| RMSE: 0.7728| MRE: 0.4086| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/pems_traffic/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: pems_traffic | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | solar_alabama | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=137)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:50:14 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:50:14 [INFO]: You're using dataset solar_alabama, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/solar_alabama
2025-08-23 10:50:14 [INFO]: Dataset solar_alabama has already been downloaded. Processing directly...
2025-08-23 10:50:14 [INFO]: Dataset solar_alabama has already been cached. Loading from cache directly...
2025-08-23 10:50:14 [INFO]: Loaded successfully!
2025-08-23 10:50:14 [INFO]: months selected as train set are <PeriodArray>
['2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06']
Length: 6, dtype: period[M]
2025-08-23 10:50:14 [INFO]: months selected as val set are <PeriodArray>
['2006-07', '2006-08', '2006-09']
Length: 3, dtype: period[M]
2025-08-23 10:50:14 [INFO]: months selected as test set are <PeriodArray>
['2006-10', '2006-11', '2006-12']
Length: 3, dtype: period[M]
2025-08-23 10:50:15 [INFO]: Total sample number: 547
2025-08-23 10:50:15 [INFO]: Training set size: 271 (49.54%)
2025-08-23 10:50:15 [INFO]: Validation set size: 138 (25.23%)
2025-08-23 10:50:15 [INFO]: Test set size: 138 (25.23%)
2025-08-23 10:50:15 [INFO]: Number of steps: 96
2025-08-23 10:50:15 [INFO]: Number of features: 137
2025-08-23 10:50:15 [INFO]: Train set missing rate: 9.98%
2025-08-23 10:50:15 [INFO]: Validating set missing rate: 9.94%
2025-08-23 10:50:15 [INFO]: Test set missing rate: 9.99%
✅ Dataset 'solar_alabama' with missing rate 0.1 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.1
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:50:15 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:50:15 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:50:15 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:50:15 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:50:15 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:50:15 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:50:17 [INFO]: Model placed on cuda:6
2025-08-23 10:50:17 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,954,121
 ├─ Trainable parameters: 1,213,577
 └─ Trainable ratio: 2.58%
2025-08-23 10:50:19 [INFO]: Epoch 001 - training loss (MAE): 0.4091, validation MSE: 0.1463
2025-08-23 10:50:19 [INFO]: Epoch 002 - training loss (MAE): 0.2715, validation MSE: 0.1168
2025-08-23 10:50:20 [INFO]: Epoch 003 - training loss (MAE): 0.2423, validation MSE: 0.0975
2025-08-23 10:50:20 [INFO]: Epoch 004 - training loss (MAE): 0.2162, validation MSE: 0.0774
2025-08-23 10:50:21 [INFO]: Epoch 005 - training loss (MAE): 0.1933, validation MSE: 0.0699
2025-08-23 10:50:21 [INFO]: Epoch 006 - training loss (MAE): 0.1799, validation MSE: 0.0709
2025-08-23 10:50:22 [INFO]: Epoch 007 - training loss (MAE): 0.1712, validation MSE: 0.0648
2025-08-23 10:50:22 [INFO]: Epoch 008 - training loss (MAE): 0.1629, validation MSE: 0.0690
2025-08-23 10:50:23 [INFO]: Epoch 009 - training loss (MAE): 0.1582, validation MSE: 0.0646
2025-08-23 10:50:24 [INFO]: Epoch 010 - training loss (MAE): 0.1527, validation MSE: 0.0680
2025-08-23 10:50:24 [INFO]: Epoch 011 - training loss (MAE): 0.1513, validation MSE: 0.0602
2025-08-23 10:50:25 [INFO]: Epoch 012 - training loss (MAE): 0.1492, validation MSE: 0.0613
2025-08-23 10:50:26 [INFO]: Epoch 013 - training loss (MAE): 0.1449, validation MSE: 0.0587
2025-08-23 10:50:26 [INFO]: Epoch 014 - training loss (MAE): 0.1437, validation MSE: 0.0649
2025-08-23 10:50:27 [INFO]: Epoch 015 - training loss (MAE): 0.1416, validation MSE: 0.0561
2025-08-23 10:50:27 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:50:27 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1149| MSE: 0.0369| RMSE: 0.1920| MRE: 0.1483| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: solar_alabama | mr0.1_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | solar_alabama | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=137)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:50:50 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:50:50 [INFO]: You're using dataset solar_alabama, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/solar_alabama
2025-08-23 10:50:50 [INFO]: Dataset solar_alabama has already been downloaded. Processing directly...
2025-08-23 10:50:50 [INFO]: Dataset solar_alabama has already been cached. Loading from cache directly...
2025-08-23 10:50:51 [INFO]: Loaded successfully!
2025-08-23 10:50:51 [INFO]: months selected as train set are <PeriodArray>
['2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06']
Length: 6, dtype: period[M]
2025-08-23 10:50:51 [INFO]: months selected as val set are <PeriodArray>
['2006-07', '2006-08', '2006-09']
Length: 3, dtype: period[M]
2025-08-23 10:50:51 [INFO]: months selected as test set are <PeriodArray>
['2006-10', '2006-11', '2006-12']
Length: 3, dtype: period[M]
2025-08-23 10:50:51 [INFO]: Total sample number: 547
2025-08-23 10:50:51 [INFO]: Training set size: 271 (49.54%)
2025-08-23 10:50:51 [INFO]: Validation set size: 138 (25.23%)
2025-08-23 10:50:51 [INFO]: Test set size: 138 (25.23%)
2025-08-23 10:50:51 [INFO]: Number of steps: 96
2025-08-23 10:50:51 [INFO]: Number of features: 137
2025-08-23 10:50:51 [INFO]: Train set missing rate: 20.00%
2025-08-23 10:50:51 [INFO]: Validating set missing rate: 19.95%
2025-08-23 10:50:51 [INFO]: Test set missing rate: 20.01%
✅ Dataset 'solar_alabama' with missing rate 0.2 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.2
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:50:51 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:50:51 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:50:52 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:50:52 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:50:52 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:50:52 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:50:54 [INFO]: Model placed on cuda:6
2025-08-23 10:50:54 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,954,121
 ├─ Trainable parameters: 1,213,577
 └─ Trainable ratio: 2.58%
2025-08-23 10:50:56 [INFO]: Epoch 001 - training loss (MAE): 0.4139, validation MSE: 0.1601
2025-08-23 10:50:56 [INFO]: Epoch 002 - training loss (MAE): 0.2737, validation MSE: 0.1175
2025-08-23 10:50:57 [INFO]: Epoch 003 - training loss (MAE): 0.2455, validation MSE: 0.1028
2025-08-23 10:50:57 [INFO]: Epoch 004 - training loss (MAE): 0.2212, validation MSE: 0.0856
2025-08-23 10:50:58 [INFO]: Epoch 005 - training loss (MAE): 0.1983, validation MSE: 0.0735
2025-08-23 10:50:59 [INFO]: Epoch 006 - training loss (MAE): 0.1855, validation MSE: 0.0696
2025-08-23 10:50:59 [INFO]: Epoch 007 - training loss (MAE): 0.1761, validation MSE: 0.0703
2025-08-23 10:51:00 [INFO]: Epoch 008 - training loss (MAE): 0.1674, validation MSE: 0.0678
2025-08-23 10:51:00 [INFO]: Epoch 009 - training loss (MAE): 0.1624, validation MSE: 0.0674
2025-08-23 10:51:01 [INFO]: Epoch 010 - training loss (MAE): 0.1573, validation MSE: 0.0698
2025-08-23 10:51:02 [INFO]: Epoch 011 - training loss (MAE): 0.1559, validation MSE: 0.0627
2025-08-23 10:51:02 [INFO]: Epoch 012 - training loss (MAE): 0.1541, validation MSE: 0.0634
2025-08-23 10:51:03 [INFO]: Epoch 013 - training loss (MAE): 0.1501, validation MSE: 0.0616
2025-08-23 10:51:04 [INFO]: Epoch 014 - training loss (MAE): 0.1486, validation MSE: 0.0660
2025-08-23 10:51:04 [INFO]: Epoch 015 - training loss (MAE): 0.1469, validation MSE: 0.0572
2025-08-23 10:51:04 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:51:04 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1161| MSE: 0.0380| RMSE: 0.1949| MRE: 0.1499| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: solar_alabama | mr0.2_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | solar_alabama | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=137)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:51:23 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
2025-08-23 10:51:23 [INFO]: You're using dataset solar_alabama, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/solar_alabama
2025-08-23 10:51:23 [INFO]: Dataset solar_alabama has already been downloaded. Processing directly...
2025-08-23 10:51:23 [INFO]: Dataset solar_alabama has already been cached. Loading from cache directly...
2025-08-23 10:51:23 [INFO]: Loaded successfully!
2025-08-23 10:51:23 [INFO]: months selected as train set are <PeriodArray>
['2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06']
Length: 6, dtype: period[M]
2025-08-23 10:51:23 [INFO]: months selected as val set are <PeriodArray>
['2006-07', '2006-08', '2006-09']
Length: 3, dtype: period[M]
2025-08-23 10:51:23 [INFO]: months selected as test set are <PeriodArray>
['2006-10', '2006-11', '2006-12']
Length: 3, dtype: period[M]
2025-08-23 10:51:24 [INFO]: Total sample number: 547
2025-08-23 10:51:24 [INFO]: Training set size: 271 (49.54%)
2025-08-23 10:51:24 [INFO]: Validation set size: 138 (25.23%)
2025-08-23 10:51:24 [INFO]: Test set size: 138 (25.23%)
2025-08-23 10:51:24 [INFO]: Number of steps: 96
2025-08-23 10:51:24 [INFO]: Number of features: 137
2025-08-23 10:51:24 [INFO]: Train set missing rate: 30.02%
2025-08-23 10:51:24 [INFO]: Validating set missing rate: 29.94%
2025-08-23 10:51:24 [INFO]: Test set missing rate: 30.02%
✅ Dataset 'solar_alabama' with missing rate 0.3 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.3
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:51:24 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:51:24 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:51:24 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:51:24 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:51:24 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:51:24 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:51:26 [INFO]: Model placed on cuda:6
2025-08-23 10:51:26 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,954,121
 ├─ Trainable parameters: 1,213,577
 └─ Trainable ratio: 2.58%
2025-08-23 10:51:28 [INFO]: Epoch 001 - training loss (MAE): 0.4203, validation MSE: 0.1752
2025-08-23 10:51:29 [INFO]: Epoch 002 - training loss (MAE): 0.2779, validation MSE: 0.1202
2025-08-23 10:51:30 [INFO]: Epoch 003 - training loss (MAE): 0.2497, validation MSE: 0.1090
2025-08-23 10:51:30 [INFO]: Epoch 004 - training loss (MAE): 0.2268, validation MSE: 0.0919
2025-08-23 10:51:30 [INFO]: Epoch 005 - training loss (MAE): 0.2050, validation MSE: 0.0801
2025-08-23 10:51:31 [INFO]: Epoch 006 - training loss (MAE): 0.1916, validation MSE: 0.0705
2025-08-23 10:51:32 [INFO]: Epoch 007 - training loss (MAE): 0.1827, validation MSE: 0.0702
2025-08-23 10:51:32 [INFO]: Epoch 008 - training loss (MAE): 0.1737, validation MSE: 0.0721
2025-08-23 10:51:33 [INFO]: Epoch 009 - training loss (MAE): 0.1688, validation MSE: 0.0706
2025-08-23 10:51:33 [INFO]: Epoch 010 - training loss (MAE): 0.1637, validation MSE: 0.0725
2025-08-23 10:51:34 [INFO]: Epoch 011 - training loss (MAE): 0.1619, validation MSE: 0.0683
2025-08-23 10:51:34 [INFO]: Epoch 012 - training loss (MAE): 0.1605, validation MSE: 0.0645
2025-08-23 10:51:35 [INFO]: Epoch 013 - training loss (MAE): 0.1563, validation MSE: 0.0671
2025-08-23 10:51:35 [INFO]: Epoch 014 - training loss (MAE): 0.1545, validation MSE: 0.0690
2025-08-23 10:51:35 [INFO]: Epoch 015 - training loss (MAE): 0.1528, validation MSE: 0.0628
2025-08-23 10:51:35 [INFO]: Finished training. The best model is from epoch#15.
2025-08-23 10:51:36 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1266| MSE: 0.0430| RMSE: 0.2073| MRE: 0.1634| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: solar_alabama | mr0.3_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | solar_alabama | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=137)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:51:55 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:51:55 [INFO]: You're using dataset solar_alabama, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/solar_alabama
2025-08-23 10:51:55 [INFO]: Dataset solar_alabama has already been downloaded. Processing directly...
2025-08-23 10:51:55 [INFO]: Dataset solar_alabama has already been cached. Loading from cache directly...
2025-08-23 10:51:55 [INFO]: Loaded successfully!
2025-08-23 10:51:55 [INFO]: months selected as train set are <PeriodArray>
['2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06']
Length: 6, dtype: period[M]
2025-08-23 10:51:55 [INFO]: months selected as val set are <PeriodArray>
['2006-07', '2006-08', '2006-09']
Length: 3, dtype: period[M]
2025-08-23 10:51:55 [INFO]: months selected as test set are <PeriodArray>
['2006-10', '2006-11', '2006-12']
Length: 3, dtype: period[M]
2025-08-23 10:51:55 [INFO]: Total sample number: 547
2025-08-23 10:51:55 [INFO]: Training set size: 271 (49.54%)
2025-08-23 10:51:55 [INFO]: Validation set size: 138 (25.23%)
2025-08-23 10:51:55 [INFO]: Test set size: 138 (25.23%)
2025-08-23 10:51:55 [INFO]: Number of steps: 96
2025-08-23 10:51:55 [INFO]: Number of features: 137
2025-08-23 10:51:55 [INFO]: Train set missing rate: 40.00%
2025-08-23 10:51:55 [INFO]: Validating set missing rate: 39.97%
✅ Dataset 'solar_alabama' with missing rate 0.4 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.4
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:51:55 [INFO]: Test set missing rate: 40.00%
2025-08-23 10:51:56 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:51:56 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:51:56 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:51:56 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:51:56 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:51:56 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:51:58 [INFO]: Model placed on cuda:6
2025-08-23 10:51:58 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,954,121
 ├─ Trainable parameters: 1,213,577
 └─ Trainable ratio: 2.58%
2025-08-23 10:52:00 [INFO]: Epoch 001 - training loss (MAE): 0.4278, validation MSE: 0.2024
2025-08-23 10:52:00 [INFO]: Epoch 002 - training loss (MAE): 0.2821, validation MSE: 0.1233
2025-08-23 10:52:01 [INFO]: Epoch 003 - training loss (MAE): 0.2538, validation MSE: 0.1157
2025-08-23 10:52:01 [INFO]: Epoch 004 - training loss (MAE): 0.2322, validation MSE: 0.0959
2025-08-23 10:52:02 [INFO]: Epoch 005 - training loss (MAE): 0.2116, validation MSE: 0.0873
2025-08-23 10:52:02 [INFO]: Epoch 006 - training loss (MAE): 0.1987, validation MSE: 0.0782
2025-08-23 10:52:03 [INFO]: Epoch 007 - training loss (MAE): 0.1902, validation MSE: 0.0735
2025-08-23 10:52:04 [INFO]: Epoch 008 - training loss (MAE): 0.1819, validation MSE: 0.0746
2025-08-23 10:52:04 [INFO]: Epoch 009 - training loss (MAE): 0.1764, validation MSE: 0.0758
2025-08-23 10:52:05 [INFO]: Epoch 010 - training loss (MAE): 0.1716, validation MSE: 0.0793
2025-08-23 10:52:05 [INFO]: Epoch 011 - training loss (MAE): 0.1697, validation MSE: 0.0737
2025-08-23 10:52:06 [INFO]: Epoch 012 - training loss (MAE): 0.1683, validation MSE: 0.0688
2025-08-23 10:52:07 [INFO]: Epoch 013 - training loss (MAE): 0.1636, validation MSE: 0.0688
2025-08-23 10:52:07 [INFO]: Epoch 014 - training loss (MAE): 0.1622, validation MSE: 0.0735
2025-08-23 10:52:08 [INFO]: Epoch 015 - training loss (MAE): 0.1610, validation MSE: 0.0705
2025-08-23 10:52:08 [INFO]: Finished training. The best model is from epoch#12.
2025-08-23 10:52:08 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1297| MSE: 0.0469| RMSE: 0.2167| MRE: 0.1676| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: solar_alabama | mr0.4_bs32_dm64_ffn64_h2_ly1_proftrue
🔥 RUN: gpt4ts | solar_alabama | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue (DEVICE=cuda:6, N_STEPS=96, N_FEATURES=137)
[34m
████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗
╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║
   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║
   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║
   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║
   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝
ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai [0m

Use Train GPT: False
Use Lora: False
Use Profiling: True
2025-08-23 10:52:16 [INFO]: Have set the random seed as 2025 for numpy and pytorch.
🚀 Running imputation pipeline for model: gpt4ts
ℹ️ TSDB migration not needed, directory exists: /home/23r8105_messou/lab/iPyPOTS/datasets
2025-08-23 10:52:16 [INFO]: You're using dataset solar_alabama, please cite it properly in your work. You can find its reference information at the below link: 
https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/solar_alabama
2025-08-23 10:52:16 [INFO]: Dataset solar_alabama has already been downloaded. Processing directly...
2025-08-23 10:52:16 [INFO]: Dataset solar_alabama has already been cached. Loading from cache directly...
2025-08-23 10:52:16 [INFO]: Loaded successfully!
2025-08-23 10:52:16 [INFO]: months selected as train set are <PeriodArray>
['2006-01', '2006-02', '2006-03', '2006-04', '2006-05', '2006-06']
Length: 6, dtype: period[M]
2025-08-23 10:52:16 [INFO]: months selected as val set are <PeriodArray>
['2006-07', '2006-08', '2006-09']
Length: 3, dtype: period[M]
2025-08-23 10:52:16 [INFO]: months selected as test set are <PeriodArray>
['2006-10', '2006-11', '2006-12']
Length: 3, dtype: period[M]
2025-08-23 10:52:17 [INFO]: Total sample number: 547
2025-08-23 10:52:17 [INFO]: Training set size: 271 (49.54%)
2025-08-23 10:52:17 [INFO]: Validation set size: 138 (25.23%)
2025-08-23 10:52:17 [INFO]: Test set size: 138 (25.23%)
2025-08-23 10:52:17 [INFO]: Number of steps: 96
2025-08-23 10:52:17 [INFO]: Number of features: 137
2025-08-23 10:52:17 [INFO]: Train set missing rate: 49.99%
2025-08-23 10:52:17 [INFO]: Validating set missing rate: 50.03%
2025-08-23 10:52:17 [INFO]: Test set missing rate: 50.02%
✅ Dataset 'solar_alabama' with missing rate 0.5 loaded at: /home/23r8105_messou/lab/iPyPOTS/datasets/rate_0.5
🚀 Starting GPT4TS training pipeline...
2025-08-23 10:52:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using device list: ['cuda:6']
2025-08-23 10:52:17 [INFO]: 🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥Using the given device: cuda:6
2025-08-23 10:52:17 [INFO]: Model files will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
2025-08-23 10:52:17 [INFO]: Tensorboard file will be saved to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/tensorboard
2025-08-23 10:52:17 [INFO]: Using customized MAE as the training loss function.
2025-08-23 10:52:17 [INFO]: Using customized MSE as the validation metric function.
2025-08-23 10:52:18 [INFO]: Model placed on cuda:6
2025-08-23 10:52:18 [INFO]: GPT4TS initialized with the given hyperparameters.
 ├─ Total parameters: 46,954,121
 ├─ Trainable parameters: 1,213,577
 └─ Trainable ratio: 2.58%
2025-08-23 10:52:20 [INFO]: Epoch 001 - training loss (MAE): 0.4388, validation MSE: 0.2320
2025-08-23 10:52:20 [INFO]: Epoch 002 - training loss (MAE): 0.2866, validation MSE: 0.1291
2025-08-23 10:52:21 [INFO]: Epoch 003 - training loss (MAE): 0.2592, validation MSE: 0.1244
2025-08-23 10:52:21 [INFO]: Epoch 004 - training loss (MAE): 0.2385, validation MSE: 0.1014
2025-08-23 10:52:22 [INFO]: Epoch 005 - training loss (MAE): 0.2184, validation MSE: 0.0964
2025-08-23 10:52:22 [INFO]: Epoch 006 - training loss (MAE): 0.2061, validation MSE: 0.0896
2025-08-23 10:52:23 [INFO]: Epoch 007 - training loss (MAE): 0.1985, validation MSE: 0.0807
2025-08-23 10:52:24 [INFO]: Epoch 008 - training loss (MAE): 0.1902, validation MSE: 0.0793
2025-08-23 10:52:24 [INFO]: Epoch 009 - training loss (MAE): 0.1853, validation MSE: 0.0787
2025-08-23 10:52:25 [INFO]: Epoch 010 - training loss (MAE): 0.1808, validation MSE: 0.0829
2025-08-23 10:52:25 [INFO]: Epoch 011 - training loss (MAE): 0.1787, validation MSE: 0.0817
2025-08-23 10:52:26 [INFO]: Epoch 012 - training loss (MAE): 0.1775, validation MSE: 0.0788
2025-08-23 10:52:26 [INFO]: Epoch 013 - training loss (MAE): 0.1730, validation MSE: 0.0744
2025-08-23 10:52:27 [INFO]: Epoch 014 - training loss (MAE): 0.1718, validation MSE: 0.0759
2025-08-23 10:52:27 [INFO]: Epoch 015 - training loss (MAE): 0.1706, validation MSE: 0.0798
2025-08-23 10:52:27 [INFO]: Finished training. The best model is from epoch#13.
2025-08-23 10:52:27 [INFO]: Saved the model to output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/GPT4TS.pypots
[GPT4TS] Testing —— MAE: 0.1347| MSE: 0.0506| RMSE: 0.2250| MRE: 0.1738| 
📊 Metrics saved to: output/imputation/cuda:6/gpt4ts/solar_alabama/epoch15/mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue/metrics/gpt4ts_metrics.json
✅ DONE: solar_alabama | mr0.5_bs32_dm64_ffn64_h2_ly1_proftrue
✅ All gpt4ts runs completed at 2025-08-23T10:52:30+09:00.
